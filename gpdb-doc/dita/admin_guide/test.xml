<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic1" xml:lang="en">
  <title id="im138244">Defining Database Objects</title>
  <shortdesc>This section covers data definition language (DDL) in Greenplum Database and how to
    create and manage database objects.</shortdesc>
  <body>
    <p>Creating objects in a Greenplum Database includes making up-front choices about data
      distribution, storage options, data loading, and other Greenplum features that will affect the
      ongoing performance of your database system. Understanding the options that are available and
      how the database will be used will help you make the right choices. </p>
    <p>Most of the advanced Greenplum features are enabled with extensions to the SQL
        <codeph>CREATE</codeph> DDL statements. </p>
  </body>
  <topic id="topic2" xml:lang="en">
    <title id="im140249">Creating and Managing Databases</title>
    <body>
      <p rev="true">A Greenplum Database system is a single instance of Greenplum Database. There
        can be several separate Greenplum Database systems installed, but usually just one is
        selected by environment variable settings. See your Greenplum administrator for details.</p>
      <p>There can be multiple databases in a Greenplum Database system. This is different from some
        database management systems (such as Oracle) where the database instance <i>is</i> the
        database. Although you can create many databases in a Greenplum system, client programs can
        connect to and access only one database at a time &#8212; you cannot cross-query between
        databases.</p>
    </body>
    <topic id="topic3" xml:lang="en">
      <title id="im140508">About Template Databases</title>
      <body>
        <p>Each new database you create is based on a <i>template</i>. Greenplum provides a default
          database, <i>template1</i>. Use <i>template1</i> to connect to Greenplum Database for the
          first time. Greenplum Database uses <i>template1</i> to create databases unless you
          specify another template. Do not create any objects in <i>template1</i> unless you want
          those objects to be in every database you create. </p>
        <p>Greenplum uses two other database templates, <i>template0</i> and <i>postgres</i>,
          internally. Do not drop or modify <i>template0</i> or <i>postgres</i>. You can use
            <i>template0</i> to create a completely clean database containing only the standard
          objects predefined by Greenplum Database at initialization, especially if you modified
            <i>template1</i>.</p>
      </body>
    </topic>
    <topic id="topic4" xml:lang="en">
      <title>Creating a Database</title>
      <body>
        <p>The <codeph>CREATE DATABASE</codeph> command creates a new database. For example:</p>
        <p>
          <codeblock>=&gt; CREATE DATABASE <i>new_dbname</i>;</codeblock>
        </p>
        <p>To create a database, you must have privileges to create a database or be a Greenplum
          superuser. If you do not have the correct privileges, you cannot create a database.
          Contact your Greenplum administrator to either give you the necessary privilege or to
          create a database for you.</p>
        <p>You can also use the client program <codeph>createdb</codeph> to create a database. For
          example, running the following command in a command line terminal connects to Greenplum
          Database using the provided host name and port and creates a database named
            <i>mydatabase</i>:</p>
        <p>
          <codeblock>$ createdb -h masterhost -p 5432 mydatabase</codeblock>
        </p>
        <p>The host name and port must match the host name and port of the installed Greenplum
          Database system.</p>
        <p>Some objects, such as roles, are shared by all the databases in a Greenplum Database
          system. Other objects, such as tables that you create, are known only in the database in
          which you create them.</p>
      </body>
      <topic id="topic5" xml:lang="en">
        <title>Cloning a Database</title>
        <body>
          <p>By default, a new database is created by cloning the standard system database template,
              <i>template1</i>. Any database can be used as a template when creating a new database,
            thereby providing the capability to 'clone' or copy an existing database and all objects
            and data within that database. For example:</p>
          <p>
            <codeblock>=&gt; CREATE DATABASE <i>new_dbname</i> TEMPLATE <i>old_dbname</i>;</codeblock>
          </p>
        </body>
      </topic>
    </topic>
    <topic id="topic6" xml:lang="en">
      <title>Viewing the List of Databases</title>
      <body>
        <p>If you are working in the <codeph>psql</codeph> client program, you can use the
            <codeph>\l</codeph> meta-command to show the list of databases and templates in your
          Greenplum Database system. If using another client program and you are a superuser, you
          can query the list of databases from the <codeph>pg_database</codeph> system catalog
          table. For example:</p>
        <p>
          <codeblock>=&gt; SELECT datname from pg_database;</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic7" xml:lang="en">
      <title>Altering a Database</title>
      <body>
        <p>The <ph>ALTER DATABASE</ph> command changes database attributes such as owner, name, or
          default configuration attributes. For example, the following command alters a database by
          setting its default schema search path (the <codeph>search_path</codeph> configuration
          parameter):</p>
        <p>
          <codeblock>=&gt; ALTER DATABASE mydatabase SET search_path TO myschema, public, pg_catalog;</codeblock>
        </p>
        <p>To alter a database, you must be the owner of the database or a superuser. </p>
      </body>
    </topic>
    <topic id="topic8" xml:lang="en">
      <title>Dropping a Database</title>
      <body>
        <p>The <codeph>DROP DATABASE</codeph> command drops (or deletes) a database. It removes the
          system catalog entries for the database and deletes the database directory on disk that
          contains the data. You must be the database owner or a superuser to drop a database, and
          you cannot drop a database while you or anyone else is connected to it. Connect to
            <codeph>template1</codeph> (or another database) before dropping a database. For
          example:</p>
        <p>
          <codeblock>=&gt; \c template1
=&gt; DROP DATABASE mydatabase;</codeblock>
        </p>
        <p>You can also use the client program <codeph>dropdb</codeph> to drop a database. For
          example, the following command connects to Greenplum Database using the provided host name
          and port and drops the database <i>mydatabase</i>:</p>
        <p>
          <codeblock>$ dropdb -h masterhost -p 5432 mydatabase</codeblock>
        </p>
        <note type="warning">Dropping a database cannot be undone.</note>
      </body>
    </topic>
  </topic>
  <topic id="topic9" xml:lang="en">
    <title id="im140259">Creating and Managing Tablespaces</title>
    <body>
      <p>Tablespaces allow database administrators to have multiple file systems per machine and
        decide how to best use physical storage to store database objects. They are named locations
        within a filespace in which you can create objects. Tablespaces allow you to assign
        different storage for frequently and infrequently used database objects or to control the
        I/O performance on certain database objects. For example, place frequently-used tables on
        file systems that use high performance solid-state drives (SSD), and place other tables on
        standard hard drives.</p>
      <p>A tablespace requires a file system location to store its database files. In Greenplum
        Database, the master and each segment (primary and mirror) require a distinct storage
        location. The collection of file system locations for all components in a Greenplum system
        is a <i>filespace</i>. Filespaces can be used by one or more tablespaces.</p>
    </body>
    <topic id="topic10" xml:lang="en">
      <title id="im199401">Creating a Filespace</title>
      <body>
        <p>A filespace sets aside storage for your Greenplum system. A filespace is a symbolic
          storage identifier that maps onto a set of locations in your Greenplum hosts' file
          systems. To create a filespace, prepare the logical file systems on all of your Greenplum
          hosts, then use the <codeph>gpfilespace</codeph> utility to define the filespace. You must
          be a database superuser to create a filespace.</p>
        <note type="note">Greenplum Database is not directly aware of the file system boundaries on
          your underlying systems. It stores files in the directories that you tell it to use. You
          cannot control the location on disk of individual files within a logical file
          system.</note>
        <section id="im178954">
          <title>To create a filespace using gpfilespace</title>
          <ol>
            <li id="im178990">Log in to the Greenplum Database master as the
                <codeph>gpadmin</codeph>
              user.<codeblock>$ su - <codeph>gpadmin</codeph></codeblock></li>
            <li id="im178959">Create a filespace configuration
              file:<codeblock>$ gpfilespace -o gpfilespace_config</codeblock></li>
            <li id="im179004">At the prompt, enter a name for the filespace, the primary segment
              file system locations, the mirror segment file system locations, and a master file
              system location. For example, if your configuration has 2 primary and 2 mirror
              segments per
              host:<codeblock>Enter a name for this filespace&gt; fastdisk
primary location 1&gt; <i>/gpfs1/seg1
</i>primary location 2&gt; <i>/gpfs1/seg2
</i>mirror location 1&gt; <i>/gpfs2/mir1
</i>mirror location 2&gt; <i>/gpfs2/mir2
</i>master location&gt; <i>/gpfs1/master
</i></codeblock></li>
            <li id="im179011">gpfilespace creates a configuration file. Examine the file to verify
              that the gpfilespace <ph>configuration</ph> is correct. </li>
            <li id="im179508">Run gpfilespace again to create the filespace based on the
              configuration
              file:<p><codeblock>$ gpfilespace -c gpfilespace_config</codeblock></p></li>
          </ol>
        </section>
      </body>
    </topic>
    <topic id="topic11" xml:lang="en">
      <title>Moving the Location of Temporary or Transaction Files</title>
      <body>
        <p>You can move temporary or transaction files to a specific filespace to improve database
          performance when running queries, creating backups, and to store data more sequentially. </p>
        <p>The dedicated filespace for temporary and transaction files is tracked in two separate
          flat files called gp_temporary_files_filespace and gp_transaction_files_filespace. These
          are located in the pg_system directory on each primary and mirror segment, and on master
          and standby. You must be a superuser to move temporary or transaction files. Only the
            <codeph>gpfilespace</codeph> utility can write to this file.</p>
      </body>
      <topic id="topic12" xml:lang="en">
        <title>About Temporary and Transaction Files</title>
        <body>
          <p>Unless otherwise specified, temporary and transaction files are stored together with
            all user data. The default location of temporary files,
              <i>&lt;filespace_directory&gt;</i>/<i>&lt;tablespace_oid&gt;</i>/<i>&lt;database_oid&gt;</i>/pgsql_tmp
            is changed when you use <codeph>gpfilespace --movetempfiles</codeph> for the first time. </p>
          <p>Also note the following information about temporary or transaction files:</p>
          <ul>
            <li id="im198887">You can dedicate only one filespace for temporary or transaction
              files, although you can use the same filespace to store other types of files.</li>
            <li id="im198888">You cannot drop a filespace if it used by temporary files.</li>
            <li id="im198892">You must create the filespace in advance. See <xref href="#topic10" type="topic" format="dita"/>.</li>
          </ul>
          <section id="im198893">
            <title>To move temporary files using gpfilespace</title>
            <ol>
              <li id="im198894">Check that the filespace exists and is different from the filespace
                used to store all other user data.</li>
              <li id="im198895">Issue smart shutdown to bring the Greenplum Database offline.<p>If
                  any connections are still in progess,the gpfilespace --movetempfiles utility will
                  fail.</p></li>
              <li id="im198897">Bring Greenplum Database online with no active session and run the
                following
                  command:<p><codeblock>gpfilespace --movetempfilespace filespace_name</codeblock></p><p>The
                  location of the temporary files is stored in the segment configuration shared
                  memory (PMModuleState) and used whenever temporary files are created, opened, or
                  dropped.</p></li>
            </ol>
            <title>To move transaction files using gpfilespace</title>
            <ol>
              <li id="im198901">Check that the filespace exists and is different from the filespace
                used to store all other user data.</li>
              <li id="im198902">Issue smart shutdown to bring the Greenplum Database offline.<p>If
                  any connections are still in progess,the <codeph>gpfilespace
                    --movetransfiles</codeph> utility will fail.</p></li>
              <li id="im198904">Bring Greenplum Database online with no active session and run the
                following
                  command:<p><codeblock>gpfilespace --movetransfilespace filespace_name</codeblock></p><p>The
                  location of the transaction files is stored in the segment configuration shared
                  memory (PMModuleState) and used whenever transaction files are created, opened, or
                  dropped.</p></li>
            </ol>
          </section>
        </body>
      </topic>
    </topic>
    <topic id="topic13" xml:lang="en">
      <title>Creating a Tablespace</title>
      <body>
        <p>After you create a filespace, use the <codeph>CREATE TABLESPACE</codeph> command to
          define a tablespace that uses that filespace. For example:</p>
        <p>
          <codeblock>=# CREATE TABLESPACE fastspace FILESPACE fastdisk;
</codeblock>
        </p>
        <p>Database superusers define tablespaces and grant access to database users with the
            <codeph>GRANT</codeph><codeph>CREATE </codeph><ph>command</ph>. For example:</p>
        <p>
          <codeblock>=# GRANT CREATE ON TABLESPACE fastspace TO admin;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic14" xml:lang="en">
      <title>Using a Tablespace to Store Database Objects</title>
      <body>
        <p>Users with the <codeph>CREATE</codeph> privilege on a tablespace can create database
          objects in that tablespace, such as tables, indexes, and databases. The command is:</p>
        <p>
          <codeblock>CREATE TABLE tablename(options) TABLESPACE spacename
</codeblock>
        </p>
        <p>For example, the following command creates a table in the tablespace <i>space1</i>:</p>
        <p>
          <codeblock>CREATE TABLE foo(i int) TABLESPACE space1;
</codeblock>
        </p>
        <p>You can also use the <codeph>default_tablespace</codeph> parameter to specify the default
          tablespace for <codeph>CREATE TABLE</codeph> and <codeph>CREATE INDEX</codeph> commands
          that do not specify a tablespace:</p>
        <p>
          <codeblock>SET default_tablespace = space1;
CREATE TABLE foo(i int);
</codeblock>
        </p>
        <p>The tablespace associated with a database stores that database's system catalogs,
          temporary files created by server processes using that database, and is the default
          tablespace selected for tables and indexes created within the database, if no
            <codeph>TABLESPACE</codeph> is specified when the objects are created. If you do not
          specify a tablespace when you create a database, the database uses the same tablespace
          used by its template database.</p>
        <p>You can use a tablespace from any database if you have appropriate privileges.</p>
      </body>
    </topic>
    <topic id="topic15" xml:lang="en">
      <title>Viewing Existing Tablespaces and Filespaces</title>
      <body>
        <p>Every Greenplum Database system has the following default tablespaces.</p>
        <ul>
          <li id="im200050"><codeph>pg_global</codeph> for shared system catalogs.</li>
          <li id="im200067"><codeph>pg_default</codeph>, the default tablespace. Used by the
              <i>template1</i> and <i>template0</i> databases. </li>
        </ul>
        <p>These tablespaces use the system default filespace, <codeph>pg_system</codeph>, the data
          directory location created at system initialization.</p>
        <p>To see filespace information, look in the <i>pg_filespace</i> and
            <i>pg_filespace_entry</i> catalog tables. You can join these tables with
            <i>pg_tablespace</i> to see the full definition of a tablespace. For example:</p>
        <p>
          <codeblock>=# SELECT spcname as tblspc, fsname as filespc, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fsedbid as seg_dbid, fselocation as datadir 
&#160;&#160;&#160;FROM   pg_tablespace pgts, pg_filespace pgfs, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;  pg_filespace_entry pgfse 
   WHERE  pgts.spcfsoid=pgfse.fsefsoid 
          AND pgfse.fsefsoid=pgfs.oid 
   ORDER BY tblspc, seg_dbid;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic16" xml:lang="en">
      <title>Dropping Tablespaces and Filespaces</title>
      <body>
        <p>To drop a tablespace, you must be the tablespace owner or a superuser. You cannot drop a
          tablespace until all objects in all databases using the tablespace are removed.</p>
        <p>Only a superuser can drop a filespace. A filespace cannot be dropped until all
          tablespaces using that filespace are removed.</p>
        <p>The <codeph>DROP TABLESPACE</codeph> command removes an empty tablespace.</p>
        <p>The <codeph>DROP FILESPACE</codeph> command removes an empty filespace.</p>
        <note type="note">You cannot drop a filespace if it stores temporary or transaction
          files.</note>
      </body>
    </topic>
  </topic>
  <topic id="topic17" xml:lang="en">
    <title id="im177965">Creating and Managing Schemas</title>
    <body>
      <p>Schemas logically organize objects and data in a database. Schemas allow you to have more
        than one object (such as tables) with the same name in the database without conflict if the
        objects are in different schemas.</p>
    </body>
    <topic id="topic18" xml:lang="en">
      <title>The Default "Public" Schema</title>
      <body>
        <p>Every database has a default schema named <i>public</i>. If you do not create any
          schemas, objects are created in the <i>public</i> schema. All database roles (users) have
            <codeph>CREATE</codeph> and <codeph>USAGE</codeph> privileges in the <i>public</i>
          schema. When you create a schema, you grant privileges to your users to allow access to
          the schema.</p>
      </body>
    </topic>
    <topic id="topic19" xml:lang="en">
      <title>Creating a Schema</title>
      <body>
        <p>Use the <codeph>CREATE SCHEMA</codeph> command to create a new schema. For example:</p>
        <p>
          <codeblock>=&gt; CREATE SCHEMA myschema;
</codeblock>
        </p>
        <p>To create or access objects in a schema, write a qualified name consisting of the schema
          name and table name separated by a period. For example:</p>
        <p>
          <codeblock>myschema.table
</codeblock>
        </p>
        <p>See <xref href="#topic20" type="topic" format="dita"/> for information about accessing a
          schema.</p>
        <p>You can create a schema owned by someone else, for example, to restrict the activities of
          your users to well-defined namespaces. The syntax is:</p>
        <p>
          <codeblock>=&gt; CREATE SCHEMA <codeph>schemaname</codeph> AUTHORIZATION <codeph>username</codeph>;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic20" xml:lang="en">
      <title id="im142167">Schema Search Paths</title>
      <body>
        <p>To specify an object's location in a database, use the schema-qualified name. For
          example:</p>
        <p>
          <codeblock>=&gt; SELECT * FROM myschema.mytable;
</codeblock>
        </p>
        <p>You can set the <codeph>search_path</codeph> configuration parameter to specify the order
          in which to search the available schemas for objects. The schema listed first in the
          search path becomes the <i>default</i> schema. If a schema is not specified, objects are
          created in the default schema.</p>
      </body>
      <topic id="topic21" xml:lang="en">
        <title>Setting the Schema Search Path</title>
        <body>
          <p>The <codeph>search_path</codeph> configuration parameter sets the schema search order.
            The <codeph>ALTER DATABASE</codeph> command sets the search path. For example:</p>
          <p>
            <codeblock>=&gt; ALTER DATABASE mydatabase SET search_path TO myschema, 
public, pg_catalog;
</codeblock>
          </p>
          <p>You can also set <codeph>search_path</codeph> for a particular role (user) using the
              <codeph>ALTER ROLE</codeph> command. For example:</p>
          <p>
            <codeblock>=&gt; ALTER ROLE sally SET search_path TO myschema, public, 
pg_catalog;
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic22" xml:lang="en">
        <title>Viewing the Current Schema</title>
        <body>
          <p>Use the <codeph>current_schema()</codeph> function to view the current schema. For
            example:</p>
          <p>
            <codeblock>=&gt; SELECT current_schema();
</codeblock>
          </p>
          <p>Use the <codeph>SHOW</codeph> command to view the current search path. For example:</p>
          <p>
            <codeblock>=&gt; SHOW search_path;
</codeblock>
          </p>
        </body>
      </topic>
    </topic>
    <topic id="topic23" xml:lang="en">
      <title>Dropping a Schema</title>
      <body>
        <p>Use the <codeph>DROP SCHEMA</codeph> command to drop (delete) a schema. For example:</p>
        <p>
          <codeblock>=&gt; DROP SCHEMA myschema;
</codeblock>
        </p>
        <p>By default, the schema must be empty before you can drop it. To drop a schema and all of
          its objects (tables, data, functions, and so on) use:</p>
        <p>
          <codeblock>=&gt; DROP SCHEMA myschema CASCADE;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic24" xml:lang="en">
      <title>System Schemas</title>
      <body>
        <p>The following system-level schemas exist in every database:</p>
        <ul>
          <li id="im141362"><codeph>pg_catalog</codeph> contains the system catalog tables, built-in
            data types, functions, and operators. It is always part of the schema search path, even
            if it is not explicitly named in the search path.</li>
          <li id="im141363"><codeph>information_schema</codeph> consists of a standardized set of
            views that contain information about the objects in the database. These views get system
            information from the system catalog tables in a standardized way.</li>
          <li id="im141364"><codeph>pg_toast</codeph> stores large objects such as records that
            exceed the page size. This schema is used internally by the Greenplum Database system. </li>
          <li id="im141879"><codeph>pg_bitmapindex</codeph> stores bitmap index objects such as
            lists of values. This schema is used internally by the Greenplum Database system.</li>
          <li id="im180766"><codeph>pg_aoseg</codeph> stores append-optimized table objects. This
            schema is used internally by the Greenplum Database system.</li>
          <li id="im180819"><codeph>gp_toolkit</codeph> is an administrative schema that contains
            external tables, views, and functions that you can access with SQL commands. All
            database users can access <codeph>gp_toolkit</codeph> to view and query the system log
            files and other system metrics.</li>
        </ul>
      </body>
    </topic>
  </topic>
  <topic id="topic25" xml:lang="en">
    <title id="im140266">Creating and Managing Tables</title>
    <body>
      <p>Greenplum Database tables are similar to tables in any relational database, except that
        table rows are distributed across the different segments in the system. When you create a
        table, you specify the table's distribution policy.</p>
    </body>
    <topic id="topic26" xml:lang="en">
      <title>Creating a Table</title>
      <body>
        <p>The <codeph>CREATE TABLE</codeph> command creates a table and defines its structure. When
          you create a table, you define:</p>
        <ul>
          <li id="im142074">The columns of the table and their associated data types. See <xref href="#topic27" type="topic" format="dita"/>.</li>
          <li id="im142082">Any table or column constraints to limit the data that a column or table
            can contain. See <xref href="#topic28" type="topic" format="dita"/>.</li>
          <li id="im163705">The distribution policy of the table, which determines how Greenplum
            divides data is across the segments. See <xref href="#topic34" type="topic" format="dita"/>.</li>
          <li id="im163709">The way the table is stored on disk. See <xref href="#topic36" type="topic" format="dita"/>. </li>
          <li id="im170093">The table partitioning strategy for large tables. See <xref href="#topic63" type="topic" format="dita"/>.</li>
        </ul>
      </body>
      <topic id="topic27" xml:lang="en">
        <title id="im140304">Choosing Column Data Types</title>
        <body>
          <p>The data type of a column determines the types of data values the column can contain.
            Choose the data type that uses the least possible space but can still accommodate your
            data and that best constrains the data. For example, use character data types for
            strings, date or timestamp data types for dates, and numeric data types for numbers.</p>
          <p>There are no performance differences among the character data types
              <codeph>CHAR</codeph>, <codeph>VARCHAR</codeph>, and <codeph>TEXT</codeph> apart from
            the increased storage size when you use the blank-padded type. In most situations, use
              <codeph>TEXT</codeph> or <codeph>VARCHAR</codeph> rather than
            <codeph>CHAR</codeph>.</p>
          <p>Use the smallest numeric data type that will accommodate your numeric data and allow
            for future expansion. For example, using <codeph>BIGINT</codeph> for data that fits in
              <codeph>INT</codeph> or <codeph>SMALLINT</codeph> wastes storage space. If you expect
            that your data values will expand over time, consider that changing from a smaller
            datatype to a larger datatype after loading large amounts of data is costly. For
            example, if your current data values fit in a <codeph>SMALLINT</codeph> but it is likely
            that the values will expand, <codeph>INT</codeph> is the better long-term choice.</p>
          <p>Use the same data types for columns that you plan to use in cross-table joins.
            Cross-table joins usually use the primary key in one table and a foreign key in the
            other table. When the data types are different, the database must convert one of them so
            that the data values can be compared correctly, which adds unnecessary overhead.</p>
          <p>Greenplum Database has a rich set of native data types available to users. See the
              <i>Greenplum Database Reference Guide</i> for information about the built-in data
            types.</p>
        </body>
      </topic>
      <topic id="topic28" xml:lang="en">
        <title id="im140306">Setting Table and Column Constraints</title>
        <body>
          <p>You can define constraints on columns and tables to restrict the data in your tables.
            Greenplum Database support for constraints is the same as PostgreSQL with some
            limitations, including:</p>
          <ul>
            <li id="im206975"><codeph>CHECK</codeph> constraints can refer only to the table on
              which they are defined. </li>
            <li id="im206986"><codeph>UNIQUE</codeph> and <codeph>PRIMARY KEY</codeph> constraints
              must be compatible with their table&#700;s distribution key and partitioning key, if any. </li>
            <li id="im207041"><codeph>FOREIGN KEY</codeph> constraints are allowed, but not
              enforced.</li>
            <li id="im206995">Constraints that you define on partitioned tables apply to the
              partitioned table as a whole. You cannot define constraints on the individual parts of
              the table.</li>
          </ul>
        </body>
        <topic id="topic29" xml:lang="en">
          <title>Check Constraints</title>
          <body>
            <p>Check constraints allow you to specify that the value in a certain column must
              satisfy a Boolean (truth-value) expression. For example, to require positive product
              prices:</p>
            <p>
              <codeblock>=&gt; CREATE TABLE products 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;( product_no integer, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name text, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;price numeric <b>CHECK (price &gt; 0)</b> );</codeblock>
            </p>
          </body>
        </topic>
        <topic id="topic30" xml:lang="en">
          <title>Not-Null Constraints</title>
          <body>
            <p>Not-null constraints specify that a column must not assume the null value. A not-null
              constraint is always written as a column constraint. For example:</p>
            <p>
              <codeblock>=&gt; CREATE TABLE products 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;( product_no integer <b>NOT NUL</b>L,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name text <b>NOT NULL</b>,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;price numeric );
</codeblock>
            </p>
          </body>
        </topic>
        <topic id="topic31" xml:lang="en">
          <title>Unique Constraints</title>
          <body>
            <p>Unique constraints ensure that the data contained in a column or a group of columns
              is unique with respect to all the rows in the table. The table must be
              hash-distributed (not <codeph>DISTRIBUTED RANDOMLY</codeph>), and the constraint
              columns must be the same as (or a superset of) the table's distribution key columns.
              For example:</p>
            <p>
              <codeblock>=&gt; CREATE TABLE products 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;( <codeph>product_no</codeph> integer <codeph>UNIQUE</codeph>, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name text, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;price numeric)
<codeph>&#160;&#160;&#160;&#160;&#160;&#160;DISTRIBUTED BY (</codeph><codeph>product_no</codeph><codeph>)</codeph>;
</codeblock>
            </p>
          </body>
        </topic>
        <topic id="topic32" xml:lang="en">
          <title>Primary Keys</title>
          <body>
            <p>A primary key constraint is a combination of a <codeph>UNIQUE</codeph> constraint and
              a <codeph>NOT NULL</codeph> constraint. The table must be hash-distributed (not
                <codeph>DISTRIBUTED RANDOMLY</codeph>), and the primary key columns must be the same
              as (or a superset of) the table's distribution key columns. If a table has a primary
              key, this column (or group of columns) is chosen as the distribution key for the table
              by default. For example:</p>
            <p>
              <codeblock>=&gt; CREATE TABLE products 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;( <codeph>product_no</codeph> integer <codeph>PRIMARY KEY</codeph>, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name text, 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;price numeric)
<codeph>&#160;&#160;&#160;&#160;&#160;&#160;DISTRIBUTED BY (</codeph><codeph>product_no</codeph><codeph>)</codeph>;
</codeblock>
            </p>
          </body>
        </topic>
        <topic id="topic33" xml:lang="en">
          <title>Foreign Keys</title>
          <body>
            <p>Foreign keys are not supported. You can declare them, but referential integrity is
              not enforced.</p>
            <p>Foreign key constraints specify that the values in a column or a group of columns
              must match the values appearing in some row of another table to maintain referential
              integrity between two related tables. Referential integrity checks cannot be enforced
              between the distributed table segments of a Greenplum database.</p>
          </body>
        </topic>
      </topic>
      <topic id="topic34" xml:lang="en">
        <title id="im140308">Choosing the Table Distribution Policy</title>
        <body>
          <p>All Greenplum Database tables are distributed. When you create or alter a table, you
            optionally specify <codeph>DISTRIBUTED BY</codeph> (hash distribution) or
              <codeph>DISTRIBUTED RANDOMLY</codeph> (round-robin distribution) to determine the
            table row distribution.</p>
          <p>Consider the following points when deciding on a table distribution policy.</p>
          <ul>
            <li id="im143035"><b>Even Data Distribution</b> &#8212; For the best possible performance, all
              segments should contain equal portions of data. If the data is unbalanced or skewed,
              the segments with more data must work harder to perform their portion of the query
              processing. Choose a distribution key that is unique for each record, such as the
              primary key.</li>
            <li id="im143036"><b>Local and Distributed Operations</b> &#8212; Local operations are faster
              than distributed operations. Query processing is fastest if the work associated with
              join, sort, or aggregation operations is done locally, at the segment level. Work done
              at the system level requires distributing tuples across the segments, which is less
              efficient. When tables share a common distribution key, the work of joining or sorting
              on their shared distribution key columns is done locally. With a random distribution
              policy, local join operations are not an option.</li>
            <li id="im200996"><b>Even Query Processing</b> &#8212; For best performance, all segments
              should handle an equal share of the query workload. Query workload can be skewed if a
              table's data distribution policy and the query predicates are not well matched. For
              example, suppose that a sales transactions table is distributed based on a column that
              contains corporate names (the distribution key), and the hashing algorithm distributes
              the data based on those values. If a predicate in a query references a single value
              from the distribution key, query processing runs on only one segment. This works if
              your query predicates usually select data on a criteria other than corporation name.
              For queries that use corporation name in their predicates, it's possible that only one
              segment instance will handle the query workload.</li>
          </ul>
        </body>
        <topic id="topic35" xml:lang="en">
          <title>Declaring Distribution Keys</title>
          <body>
            <p><codeph>CREATE TABLE</codeph>'s optional clauses <codeph>DISTRIBUTED BY</codeph> and
                <codeph>DISTRIBUTED RANDOMLY</codeph> specify the distribution policy for a table.
              The default is a hash distribution policy that uses either the <codeph>PRIMARY
                KEY</codeph> (if the table has one) or the first column of the table as the
              distribution key. Columns with geometric or user-defined data types are not eligible
              as Greenplum distribution key columns. If a table does not have an eligible column,
              Greenplum distributes the rows randomly or in round-robin fashion.</p>
            <p>To ensure even distribution of data, choose a distribution key that is unique for
              each record. If that is not possible, choose <codeph>DISTRIBUTED RANDOMLY</codeph>.
              For example:</p>
            <p>
              <codeblock>=&gt; CREATE TABLE products
<codeph>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(name varchar(40),
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;prod_id integer,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;supplier_id integer)
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DISTRIBUTED BY (prod_id);
</codeph></codeblock>
              <codeblock>=&gt; CREATE TABLE random_stuff
<codeph>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(things text,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;doodads text,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;etc text)
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DISTRIBUTED RANDOMLY;
</codeph></codeblock>
            </p>
          </body>
        </topic>
      </topic>
    </topic>
  </topic>
  <topic id="topic36" xml:lang="en">
    <title id="im148475">Choosing the Table Storage Model</title>
    <body>
      <p>Greenplum Database supports several storage models and a mix of storage models. When you
        create a table, you choose how to store its data. This topic explains the options for table
        storage and how to choose the best storage model for your workload.</p>
      <ul>
        <li id="im168064">
          <xref href="#topic37" type="topic" format="dita"/>
        </li>
        <li id="im211316">
          <xref href="#topic38" type="topic" format="dita"/>
        </li>
        <li id="im168306">
          <xref href="#topic39" type="topic" format="dita"/>
        </li>
        <li id="im168351">
          <xref href="#topic40" type="topic" format="dita"/>
        </li>
        <li id="im168411">
          <xref href="#topic41" type="topic" format="dita"/>
        </li>
      </ul>
    </body>
    <topic id="topic37" xml:lang="en">
      <title id="im168000">Heap Storage</title>
      <body>
        <p>By default, Greenplum Database uses the same heap storage model as PostgreSQL. Heap table
          storage works best with OLTP-type workloads where the data is often modified after it is
          initially loaded. <codeph>UPDATE</codeph> and <codeph>DELETE</codeph> operations require
          storing row-level versioning information to ensure reliable database transaction
          processing. Heap tables are best suited for smaller tables, such as dimension tables, that
          are often updated after they are initially loaded.</p>
      </body>
    </topic>
    <topic id="topic38" xml:lang="en">
      <title id="im201394">Append-Optimized Storage</title>
      <body>
        <p>Append-optimized table storage works best with denormalized fact tables in a data
          warehouse environment. Denormalized fact tables are typically the largest tables in the
          system. Fact tables are usually loaded in batches and accessed by read-only queries.
          Moving large fact tables to an append-optimized storage model eliminates the storage
          overhead of the per-row update visibility information, saving about 20 bytes per row. This
          allows for a leaner and easier-to-optimize page structure. The storage model of
          append-optimized tables is optimized for bulk data loading. Single row
            <codeph>INSERT</codeph> statements are not recommended.</p>
        <section id="im168504">
          <title>To create a heap table</title>
          <p>Row-oriented heap tables are the default storage type.</p>
          <p>
            <codeblock>=&gt; CREATE TABLE foo (a int, b text) DISTRIBUTED BY (a);</codeblock>
          </p>
          <title>To create an append-optimized table</title>
          <p>Use the <codeph>WITH</codeph> clause of the <codeph>CREATE TABLE</codeph> command to
            declare the table storage options. The default is to create the table as a regular
            row-oriented heap-storage table. For example, to create an append-optimized table with
            no compression:</p>
          <p>
            <codeblock>=&gt; CREATE TABLE bar (a int, b text) 
&#160;&#160;&#160; WITH (appendonly=true)
&#160;&#160;&#160; DISTRIBUTED BY (a);</codeblock>
          </p>
          <p><codeph>UPDATE</codeph> and <codeph>DELETE</codeph> are not allowed on append-optimized
            tables in a serializable transaction and will cause the transaction to abort.
              <codeph>CLUSTER</codeph>, <codeph>DECLARE...FOR UPDATE</codeph>, and triggers are not
            supported with append-optimized tables.</p>
        </section>
      </body>
    </topic>
    <topic id="topic39" xml:lang="en">
      <title id="im168256">Choosing Row or Column-Oriented Storage</title>
      <body>
        <p>Greenplum provides a choice of storage orientation models: row, column, or a combination
          of both. This topic provides general guidelines for choosing the optimum storage
          orientation for a table. Evaluate performance using your own data and query workloads.</p>
        <ul>
          <li id="im201450">Row-oriented storage: good for OLTP types of workloads with many
            interative transactions and many columns of a single row needed all at once, so
            retrieving is efficient.</li>
          <li id="im201471">Column-oriented storage: good for data warehouse workloads with
            aggregations of data computed over a small number of columns, or for single columns that
            require regular updates without modifying other column data.</li>
        </ul>
        <p>For most general purpose or mixed workloads, row-oriented storage offers the best
          combination of flexibility and performance. However, there are use cases where a
          column-oriented storage model provides more efficient I/O and storage. Consider the
          following requirements when deciding on the storage orientation model for a table:</p>
        <ul>
          <li id="im168747"><b>Updates of table data.</b> If you load and update the table data
            frequently, choose a row-oriented heap table. Column-oriented table storage is only
            available on append-optimized tables. See <xref href="#topic37" type="topic" format="dita"/> for more information.</li>
          <li id="im170466"><b>Frequent INSERTs.</b> If rows are frequently inserted into the table,
            consider a row-oriented model. Column-oriented tables are not optimized for write
            operations, as column values for a row must be written to different places on disk.</li>
          <li id="im168960"><b>Number of columns requested in queries.</b> If you typically request
            all or the majority of columns in the <codeph>SELECT</codeph> list or
              <codeph>WHERE</codeph> clause of your queries, consider a row-oriented model.
            Column-oriented tables are best suited to queries that aggregate many values of a single
            column where the <codeph>WHERE</codeph> or <codeph>HAVING</codeph> predicate is also on
            the aggregate column. For
              example:<codeblock>SELECT SUM(salary)...</codeblock><codeblock>SELECT AVG(salary)... WHERE salary &gt; 10000</codeblock><p>Or
              where the <codeph>WHERE</codeph> predicate is on a single column and returns a
              relatively small number of rows. For
            example:</p><codeblock>SELECT salary, dept ... WHERE state='CA'</codeblock></li>
          <li id="im170487"><b>Number of columns in the table.</b> Row-oriented storage is more
            efficient when many columns are required at the same time, or when the row-size of a
            table is relatively small. Column-oriented tables can offer better query performance on
            tables with many columns where you access a small subset of columns in your
            queries.</li>
          <li id="im168797"><b>Compression.</b> Column data has the same data type, so storage size
            optimizations are available in column-oriented data that are not available in
            row-oriented data. For example, many compression schemes use the similarity of adjacent
            data to compress. However, the greater adjacent compression achieved, the more difficult
            random access can become, as data must be uncompressed to be read.</li>
        </ul>
        <section id="im169305">
          <title>To create a column-oriented table</title>
          <p>The <codeph>WITH</codeph> clause of the <codeph>CREATE TABLE</codeph> command specifies
            the table's storage options. The default is a row-oriented heap table. Tables that use
            column-oriented storage must be append-optimized tables. For example, to create a
            column-oriented table:</p>
          <p>
            <codeblock>=&gt; CREATE TABLE bar (a int, b text) 
&#160;&#160;&#160; WITH (appendonly=true, orientation=column)
&#160;&#160;&#160; DISTRIBUTED BY (a);
</codeblock>
          </p>
        </section>
      </body>
    </topic>
    <topic id="topic40" xml:lang="en">
      <title id="im168077">Using Compression (Append-Optimized Tables Only)</title>
      <body>
        <p>There are two types of in-database compression available in the Greenplum Database for
          append-optimized tables:</p>
        <ul>
          <li id="im201632">Table-level compression is applied to an entire table. </li>
          <li id="im201672">Column-level compression is applied to a specific column. You can apply
            different column-level compression algorithms to different columns.</li>
        </ul>
        <p>The following table summarizes the available compression algorithms.</p>
        <table id="im198267">
          <title>Compression Algorithms for Append-Optimized Tables</title>
          <tgroup cols="3">
            <colspec colnum="1" colname="col1" colwidth="130pt"/>
            <colspec colnum="2" colname="col2" colwidth="136pt"/>
            <colspec colnum="3" colname="col3" colwidth="110pt"/>
            <thead>
              <row>
                <entry colname="col1">Table Orientation</entry>
                <entry colname="col2">Available Compression Types</entry>
                <entry colname="col3">Supported Algorithms</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry colname="col1">Row</entry>
                <entry colname="col2">Table</entry>
                <entry colname="col3"><codeph>ZLIB</codeph> and <codeph>QUICKLZ</codeph></entry>
              </row>
              <row>
                <entry colname="col1">Column</entry>
                <entry colname="col2">Column and Table</entry>
                <entry colname="col3"><codeph>RLE_TYPE</codeph>, <codeph>ZLIB</codeph>, and
                    <codeph>QUICKLZ</codeph></entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <p>When choosing a compression type and level for append-optimized tables, consider these
          factors:</p>
        <ul>
          <li id="im201780">CPU usage. Your segment systems must have the available CPU power to
            compress and uncompress the data.</li>
          <li id="im201781">Compression ratio/disk size. Minimizing disk size is one factor, but
            also consider the time and CPU capacity required to compress and scan data. Find the
            optimal settings for efficiently compressing data without causing excessively long
            compression times or slow scan rates.</li>
          <li id="im201782">Speed of compression. QuickLZ compression generally uses less CPU
            capacity and compresses data faster at a lower compression ratio than zlib. zlib
            provides higher compression ratios at lower speeds. <p>For example, at compression level
              1 (<codeph>compresslevel=1</codeph>), QuickLZ and zlib have comparable compression
              ratios, though at different speeds. Using zlib with <codeph>compresslevel=6</codeph>
              can significantly increase the compression ratio compared to QuickLZ, though with
              lower compression speed.</p></li>
          <li id="im201783">Speed of decompression/scan rate. Performance with compressed
            append-optimized tables depends on hardware, query tuning settings, and other factors.
            Perform comparison testing to determine the actual performance in your
              environment.<note>Do not use compressed append-optimized tables on file systems that
              use compression. If the file system on which your segment data directory resides is a
              compressed file system, your append-optimized table must not use
            compression.</note></li>
        </ul>
        <p>Performance with compressed append-optimized tables depends on hardware, query tuning
          settings, and other factors. Greenplum recommends performing comparison testing to
          determine the actual performance in your environment.</p>
        <note type="note">QuickLZ compression level can only be set to level 1; no other options are
          available. Compression level with zlib can be set at values from 1 - 9. Compression level
          with RLE can be set at values from 1 - 4.<p>When an <codeph>ENCODING</codeph> clause
            conflicts with a <codeph>WITH</codeph> clause, the <codeph>ENCODING</codeph> clause has
            higher precedence than the <codeph>WITH</codeph> clause.</p></note>
        <section id="im159764">
          <title>To create a compressed table</title>
          <p>The <codeph>WITH</codeph> clause of the <codeph>CREATE TABLE</codeph> command declares
            the table storage options. Tables that use compression must be append-optimized tables.
            For example, to create an append-optimized table with zlib compression at a compression
            level of 5:</p>
          <p>
            <codeblock>=&gt; CREATE TABLE foo (a int, b text) 
&#160;&#160;&#160;WITH (appendonly=true, compresstype=zlib, compresslevel=5);
</codeblock>
          </p>
        </section>
      </body>
    </topic>
    <topic id="topic41" xml:lang="en">
      <title id="im202441">Checking the Compression and Distribution of an Append-Optimized
        Table</title>
      <body>
        <p>Greenplum provides built-in functions to check the compression ratio and the distribution
          of an append-optimized table. The functions take either the object ID or a table name. You
          can qualify the table name with a schema name.</p>
        <table id="im161827">
          <title>Functions for compressed append-optimized table metadata</title>
          <tgroup cols="3">
            <colspec colnum="1" colname="col1" colwidth="183pt"/>
            <colspec colnum="2" colname="col2" colwidth="98pt"/>
            <colspec colnum="3" colname="col3" colwidth="169pt"/>
            <thead>
              <row>
                <entry colname="col1">Function</entry>
                <entry colname="col2">Return Type</entry>
                <entry colname="col3">Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry colname="col1">get_ao_distribution(name)<p>get_ao_distribution(oid)</p></entry>
                <entry colname="col2">Set of (dbid, tuplecount) rows</entry>
                <entry colname="col3">Shows the distribution of an append-optimized table's rows
                  across the array. Returns a set of rows, each of which includes a segment
                    <i>dbid</i> and the number of tuples stored on the segment.</entry>
              </row>
              <row>
                <entry colname="col1">get_ao_compression_ratio(name)<p>get_ao_compression_ratio(oid)</p></entry>
                <entry colname="col2">float8</entry>
                <entry colname="col3">Calculates the compression ratio for a compressed
                  append-optimized table. If information is not available, this function returns a
                  value of -1.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <p>The compression ratio is returned as a common ratio. For example, a returned value of
            <codeph>3.19</codeph>, or <codeph>3.19:1</codeph>, means that the uncompressed table is
          slightly larger than three times the size of the compressed table.</p>
        <p>The distribution of the table is returned as a set of rows that indicate how many tuples
          are stored on each segment. For example, in a system with four primary segments with
            <i>dbid</i> values ranging from 0 - 3, the function returns four rows similar to the
          following:</p>
        <p>
          <codeblock>=# SELECT get_ao_distribution('lineitem_comp');
 get_ao_distribution
---------------------
(0,7500721)
(1,7501365)
(2,7499978)
(3,7497731)
(4 rows)
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic42" xml:lang="en">
      <title>Support for Run-length Encoding</title>
      <body>
        <p>Greenplum Database supports Run-length Encoding (RLE) for column-level compression. RLE
          data compression stores repeated data as a single data value and a count. For example, in
          a table with two columns, a date and a description, that contains 200,000 entries
          containing the value <codeph>date1</codeph> and 400,000 entries containing the value
            <codeph>date2</codeph>, RLE compression for the date field is similar to
            <codeph>date1&#160;200000&#160;date2&#160;400000</codeph>. RLE is not useful with files that do not
          have large sets of repeated data as it can greatly increase the file size.</p>
        <p>There are four levels of RLE compression available. The levels progressively increase the
          compression ratio, but decrease the compression speed.</p>
        <p>Greenplum Database versions 4.2.1 and later support column-oriented RLE compression. To
          backup a table with RLE compression that you intend to restore to an earlier version of
          Greenplum Database, alter the table to have no compression or a compression type supported
          in the earlier version (<codeph>ZLIB</codeph> or <codeph>QUICKLZ</codeph>) before you
          start the backup operation.</p>
        <p>In Greenplum Database 4.3.3 and later, Greenplum Database combines delta compression with
          RLE compression for data in columns of type <codeph>BIGINT</codeph>,
            <codeph>INTEGER</codeph>, <codeph>DATE</codeph>, <codeph>TIME</codeph>, or
            <codeph>TIMESTAMP</codeph>. The delta compression algorithm is based on the change
          between consecutive column values and is designed to improve compression when data is
          loaded in sorted order or when the compression is applied to data in sorted order.</p>
        <p>When Greenplum Database is upgraded to 4.3.3, these rules apply for data in columns that
          are compressed with RLE:<ul id="ul_bjj_m35_jp">
            <li>Existing column data are compressed with only RLE compression.</li>
            <li>New data are compressed with delta compression combined with RLE compression in the
              columns of type that support it.</li>
          </ul></p>
        <p>If switching the Greenplum Database binary from 4.3.3 to 4.3.2 is required, the following
          steps are recommended.</p>
        <ol id="ol_xts_bl5_jp">
          <li>Alter append-optimized, column oriented tables with RLE compression columns to use
            either no compression or a compression type <codeph>ZLIB</codeph> or
              <codeph>QUICKLZ</codeph>.</li>
          <li>Back up the database.</li>
        </ol>
        <note>If you backup a table that uses RLE column compression from a Greenplum Database
          4.3.3, you can restore the table in Greenplum Database 4.3.2. However, the compression in
          the Greenplum Database 4.3.2 is RLE compression, not RLE compression combined with delta
          compression.</note>
      </body>
    </topic>
    <topic id="topic43" xml:lang="en">
      <title id="im198634">Adding Column-level Compression</title>
      <body>
        <p>You can add the following storage directives to a column for append-optimized tables with
          row or column orientation:</p>
        <ul>
          <li id="im203149">Compression type</li>
          <li id="im203164">Compression level</li>
          <li id="im203171">Block size for a column </li>
        </ul>
        <p>Add storage directives using the <codeph>CREATE TABLE</codeph>, <codeph>ALTER
            TABLE</codeph>, and <codeph>CREATE TYPE</codeph> commands. </p>
        <p>The following table details the types of storage directives and possible values for
          each.</p>
        <table id="im198636">
          <title>Storage Directives for Column-level Compression</title>
          <tgroup cols="4">
            <colspec colnum="1" colname="col1" colwidth="87pt"/>
            <colspec colnum="2" colname="col2" colwidth="95pt"/>
            <colspec colnum="3" colname="col3" colwidth="147pt"/>
            <colspec colnum="4" colname="col4" colwidth="167.25pt"/>
            <thead>
              <row>
                <entry colname="col1">Name</entry>
                <entry colname="col2">Definition</entry>
                <entry colname="col3">Values</entry>
                <entry colname="col4">Comment</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry colname="col1">
                  <codeph>COMPRESSTYPE</codeph>
                </entry>
                <entry colname="col2">Type of compression.</entry>
                <entry colname="col3"><codeph>zlib: </codeph>deflate
                      algorithm<p><codeph>quicklz</codeph>: fast
                      compression</p><p><codeph>RLE_TYPE</codeph>: run-length encoding
                      </p><p><codeph>none</codeph>: no compression</p></entry>
                <entry colname="col4">Values are not case-sensitive.</entry>
              </row>
              <row>
                <entry colname="col1" morerows="2">
                  <codeph>COMPRESSLEVEL</codeph>
                </entry>
                <entry colname="col2" morerows="2">Compression level.</entry>
                <entry colname="col3"><codeph>zlib</codeph> compression:
                    <codeph>1</codeph>-<codeph>9</codeph></entry>
                <entry colname="col4"><codeph>1</codeph> is the fastest method with the least
                  compression. <codeph>1</codeph> is the default.<p><codeph>9</codeph> is the
                    slowest method with the most compression.</p></entry>
              </row>
              <row>
                <entry colname="col3"><codeph>QuickLZ</codeph> compression:<p><codeph>1</codeph> &#8211;
                    use compression</p></entry>
                <entry colname="col4"><codeph>1</codeph> is the default.</entry>
              </row>
              <row>
                <entry colname="col3"><codeph>RLE_TYPE</codeph> compression: <codeph>1</codeph> &#8211;
                    <codeph>4</codeph><p><codeph>1</codeph> - apply RLE
                      only</p><p><codeph>2</codeph> - apply RLE then apply zlib compression level
                    1</p><p><codeph>3</codeph> - apply RLE then apply zlib compression level
                      5</p><p><codeph>4</codeph> - apply RLE then apply zlib compression level
                  9</p></entry>
                <entry colname="col4"><codeph>1</codeph> is the fastest method with the least
                      compression.<p><codeph>4</codeph> is the slowest method with the most
                    compression. <codeph>1</codeph> is the default.</p></entry>
              </row>
              <row>
                <entry colname="col1">
                  <codeph>BLOCKSIZE</codeph>
                </entry>
                <entry colname="col2">The size in bytes for each block in the table</entry>
                <entry colname="col3">
                  <codeph>8192 &#8211; 2097152</codeph>
                </entry>
                <entry colname="col4">The value must be a multiple of 8192.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <p>The following is the format for adding storage directives.</p>
        <p>
          <codeblock>[ ENCODING ( <i>storage_directive</i> [,&#8230;] ) ] </codeblock>
        </p>
        <p>where the word ENCODING is required and the storage directive has three parts:</p>
        <ul>
          <li id="im203108">The name of the directive</li>
          <li id="im203115">An equals sign</li>
          <li id="im203122">The specification </li>
        </ul>
        <p>Separate multiple storage directives with a comma. Apply a storage directive to a single
          column or designate it as the default for all columns, as shown in the following
            <codeph>CREATE TABLE</codeph> clauses.</p>
        <p>
          <i>General Usage:</i>
        </p>
        <codeblock><i>column_name</i> <i>data_type</i> ENCODING ( <i>storage_directive </i>[, &#8230; ] ), &#8230;  
</codeblock>
        <codeblock>COLUMN <i>column_name</i> ENCODING ( <i>storage_directive</i> [, &#8230; ] ), &#8230; 
</codeblock>
        <codeblock>DEFAULT COLUMN ENCODING ( <i>storage_directive</i> [, &#8230; ] )
</codeblock>
        <p>
          <i>Example:</i>
        </p>
        <codeblock>C1 char ENCODING (compresstype=quicklz, blocksize=65536) 
</codeblock>
        <codeblock>COLUMN C1 ENCODING (compresstype=quicklz, blocksize=65536)
</codeblock>
        <codeblock>DEFAULT COLUMN ENCODING (compresstype=quicklz)
</codeblock>
      </body>
      <topic id="topic44" xml:lang="en">
        <title>
          <b>Default Compression Values</b>
        </title>
        <body>
          <p>If the compression type, compression level and block size are not defined, the default
            is no compression, and the block size is set to the Server Configuration Parameter
              <codeph>block_size</codeph>.</p>
        </body>
      </topic>
      <topic id="topic45" xml:lang="en">
        <title id="im196311">
          <b>Precedence of Compression Settings</b>
        </title>
        <body>
          <p>Column compression settings are inherited from the table level to the partition level
            to the subpartition level. The lowest-level settings have priority. </p>
          <ul>
            <li id="im196313">Column compression settings specified for subpartitions override any
              compression settings at the partition, column or table levels.</li>
            <li id="im196314">Column compression settings specified for partitions override any
              compression settings at the column or table levels.</li>
            <li id="im196315">Column compression settings specified at the table level override any
              compression settings for the entire table.</li>
            <li id="im207669">When an <codeph>ENCODING</codeph> clause conflicts with a
                <codeph>WITH</codeph> clause, the <codeph>ENCODING</codeph> clause has higher
              precedence than the <codeph>WITH</codeph> clause.</li>
          </ul>
          <note type="note">The <codeph>INHERITS</codeph> clause is not allowed in a table that
            contains a storage directive or a column reference storage directive.<p>Tables created
              using the <codeph>LIKE</codeph> clause ignore storage directive and column reference
              storage directives.</p></note>
        </body>
      </topic>
      <topic id="topic46" xml:lang="en">
        <title>
          <b>Optimal Location for Column Compression Settings</b>
        </title>
        <body>
          <p>The best practice is to set the column compression settings at the level where the data
            resides. See <xref href="#topic52" type="topic" format="dita"/>, which shows a table
            with a partition depth of 2. <codeph>RLE_TYPE</codeph> compression is added to a column
            at the subpartition level.</p>
        </body>
      </topic>
      <topic id="topic47" xml:lang="en">
        <title>
          <b>Storage Directives Examples</b>
        </title>
        <body>
          <p>The following examples show the use of storage directives in <codeph>CREATE
              TABLE</codeph> statements.</p>
        </body>
        <topic id="topic48" xml:lang="en">
          <title>Example 1 </title>
          <body>
            <p>In this example, column <codeph>c1</codeph> is compressed using <codeph>zlib</codeph>
              and uses the block size defined by the system. Column <codeph>c2</codeph> is
              compressed with <codeph>quicklz</codeph>, and uses a block size of
                <codeph>65536</codeph>. Column <codeph>c3</codeph> is not compressed and uses the
              block size defined by the system.</p>
            <codeblock>CREATE TABLE T1 (c1 int ENCODING (compresstype=zlib),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c2 char ENCODING (compresstype=quicklz, blocksize=65536),
&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c3 char  &#160;&#160;&#160;WITH (appendonly=true, orientation=column);</codeblock>
          </body>
        </topic>
        <topic id="topic49" xml:lang="en">
          <title>Example 2</title>
          <body>
            <p>In this example, column <codeph>c1</codeph> is compressed using <codeph>zlib</codeph>
              and uses the block size defined by the system. Column <codeph>c2</codeph> is
              compressed with <codeph>quicklz</codeph>, and uses a block size of
                <codeph>65536</codeph>. Column <codeph>c3</codeph> is compressed using
                <codeph>RLE_TYPE</codeph> and uses the block size defined by the system.</p>
            <codeblock>CREATE TABLE T2 (c1 int ENCODING (compresstype=zlib),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c2 char ENCODING (compresstype=quicklz, blocksize=65536),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c3 char,
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;COLUMN c3 ENCODING (RLE_TYPE)
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;)
 &#160;&#160;&#160;WITH (appendonly=true, orientation=column)</codeblock>
          </body>
        </topic>
        <topic id="topic50" xml:lang="en">
          <title>Example 3</title>
          <body>
            <p>In this example, column <codeph>c1</codeph> is compressed using <codeph>zlib</codeph>
              and uses the block size defined by the system. Column <codeph>c2</codeph> is
              compressed with <codeph>quicklz</codeph>, and uses a block size of
                <codeph>65536</codeph>. Column <codeph>c3</codeph> is compressed using
                <codeph>zlib</codeph> and uses the block size defined by the system. Note that
              column <codeph>c3</codeph> uses <codeph>zlib</codeph> (not <codeph>RLE_TYPE</codeph>)
              in the partitions, because the column storage in the partition clause has precedence
              over the storage directive in the column definition for the table.</p>
            <codeblock>CREATE TABLE T3 (c1 int ENCODING (compresstype=zlib),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c2 char ENCODING (compresstype=quicklz, blocksize=65536),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c3 char, COLUMN c3 ENCODING (compresstype=RLE_TYPE) )
 &#160;&#160;&#160;WITH (appendonly=true, orientation=column)
 &#160;&#160;&#160;PARTITION BY RANGE (c3) (START ('1900-01-01'::DATE) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
            &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;END ('2100-12-31'::DATE),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;COLUMN c3 ENCODING (zlib));</codeblock>
          </body>
        </topic>
        <topic id="topic51" xml:lang="en">
          <title>Example 4</title>
          <body>
            <p>In this example, <codeph>CREATE TABLE</codeph> assigns a storage directive to
                <codeph>c1</codeph>. Column <codeph>c2</codeph> has no storage directive and
              inherits the compression type (<codeph>quicklz</codeph>) and block size
                (<codeph>65536</codeph>) from the <codeph>DEFAULT COLUMN ENCODING</codeph>
              clause.</p>
            <p>Column <codeph>c3</codeph>'s <codeph>ENCODING</codeph> clause defines its compression
              type, <codeph>RLE_TYPE</codeph>. The <codeph>DEFAULT COLUMN ENCODING</codeph> clause
              defines <codeph>c3</codeph>'s block size, <codeph>65536</codeph>. </p>
            <p>The <codeph>ENCODING</codeph> clause defined for a specific column overrides the
                <codeph>DEFAULT ENCODING</codeph> clause, so column <codeph>c4</codeph> has a
              compress type of <codeph>none</codeph> and the default block size.</p>
            <codeblock>CREATE TABLE T4 (c1 int ENCODING (compresstype=zlib),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c2 char,
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c4 smallint ENCODING (compresstype=none),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DEFAULT COLUMN ENCODING (compresstype=quicklz,
   &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;blocksize=65536),
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;COLUMN c3 ENCODING (compresstype=RLE_TYPE)
 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;) 
&#160;&#160;&#160;WITH (appendonly=true, orientation=column);</codeblock>
          </body>
        </topic>
        <topic id="topic52" xml:lang="en">
          <title id="im196338">Example 5</title>
          <body>
            <p>This example creates an append-optimized, column-oriented table, T5. T5 has two
              partitions, <codeph>p1</codeph> and <codeph>p2</codeph>, each of which has
              subpartitions. Each subpartition has <codeph>ENCODING</codeph> clauses:</p>
            <ul>
              <li id="im209617">The <codeph>ENCODING</codeph> clause for partition
                  <codeph>p1</codeph>'s subpartition <codeph>sp1</codeph> defines column
                  <codeph>i</codeph>'s compression type as <codeph>zlib</codeph> and block size as
                65536. </li>
              <li id="im209618">The <codeph>ENCODING</codeph> clauses for partition
                  <codeph>p2</codeph>'s subpartition <codeph>sp1</codeph> defines column
                  <codeph>i</codeph>'s compression type as <codeph>rle_type</codeph> and block size
                is the default value. Column <codeph>k</codeph> uses the default compression and its
                block size is
                8192.<codeblock>CREATE TABLE T5(i int, j int, k int, l int) 
    WITH (appendonly=true, orientation=column)
    PARTITION BY range(i) SUBPARTITION BY range(j)
    (
       p1 start(1) end(2)
       ( subpartition sp1 start(1) end(2) 
         column i encoding(compresstype=zlib, blocksize=65536)
       ), 
       partition p2 start(2) end(3)
       ( subpartition sp1 start(1) end(2)
           column i encoding(compresstype=rle_type)
           column k encoding(blocksize=8192)
       )
    );</codeblock></li>
            </ul>
            <p>For an example showing how to add a compressed column to an existing table with the
                <codeph>ALTER TABLE</codeph> command, see <xref href="#topic60" type="topic" format="dita"/>.</p>
          </body>
        </topic>
      </topic>
      <topic id="topic53" xml:lang="en">
        <title>
          <b>Adding Compression in a TYPE Command</b>
        </title>
        <body>
          <p>You can define a compression type to simplify column compression statements. For
            example, the following <codeph>CREATE TYPE</codeph> command defines a compression type,
              <codeph>comptype</codeph>, that specifies <codeph>quicklz</codeph> compression. </p>
          <p>where <codeph>comptype</codeph> is defined as:</p>
          <codeblock>CREATE TYPE comptype (
 &#160;&#160;internallength = 4,
 &#160;&#160;input = comptype_in,
 &#160;&#160;output = comptype_out,
 &#160;&#160;alignment = int4,
 &#160;&#160;default = 123,
 &#160;&#160;passedbyvalue,
 &#160;&#160;compresstype="quicklz",
 &#160;&#160;blocksize=65536,
 &#160;&#160;compresslevel=1
 &#160;&#160;);</codeblock>
          <p>You can then use <codeph>comptype</codeph> in a <codeph>CREATE TABLE</codeph> command
            to specify <codeph>quicklz</codeph> compression for a column:</p>
          <codeblock>CREATE TABLE t2 (c1 comptype)
 &#160;&#160;&#160;WITH (APPENDONLY=true, ORIENTATION=column);</codeblock>
          <p>For information about creating and adding compression parameters to a type, see
              <codeph>CREATE TYPE</codeph>. For information about changing compression
            specifications in a type, see <codeph>ALTER TYPE</codeph>.</p>
        </body>
        <topic id="topic54" xml:lang="en">
          <title>Choosing Block Size</title>
          <body>
            <p>The blocksize is the size, in bytes, for each block in a table. Block sizes must be
              between 8192 and 2097152 bytes, and be a multiple of 8192. The default is 32768.</p>
            <p>Specifying large block sizes can consume large amounts of memory. Block size
              determines buffering in the storage layer. Greenplum maintains a buffer per partition,
              and per column in column-oriented tables. Tables with many partitions or columns
              consume large amounts of memory.</p>
          </body>
        </topic>
      </topic>
    </topic>
    <topic id="topic55" xml:lang="en">
      <title>Altering a Table</title>
      <body>
        <p>The <codeph>ALTER TABLE </codeph>command changes the definition of a table. Use
            <codeph>ALTER TABLE</codeph> to change table attributes such as column definitions,
          distribution policy, storage model, and partition structure (see also <xref href="#topic77" type="topic" format="dita"/>). For example, to add a not-null constraint
          to a table column:</p>
        <p>
          <codeblock>=&gt; ALTER TABLE address ALTER COLUMN street SET NOT NULL;
</codeblock>
        </p>
      </body>
      <topic id="topic56" xml:lang="en">
        <title>Altering Table Distribution</title>
        <body>
          <p><codeph>ALTER TABLE</codeph> provides options to change a table's distribution policy .
            When the table distribution options change, the table data is redistributed on disk,
            which can be resource intensive. You can also redistribute table data using the existing
            distribution policy.</p>
        </body>
      </topic>
      <topic id="topic57" xml:lang="en">
        <title>Changing the Distribution Policy</title>
        <body>
          <p>For partitioned tables, changes to the distribution policy apply recursively to the
            child partitions. This operation preserves the ownership and all other attributes of the
            table. For example, the following command redistributes the table sales across all
            segments using the customer_id column as the distribution key:</p>
          <p>
            <codeblock>ALTER TABLE sales SET DISTRIBUTED BY (customer_id); 
</codeblock>
          </p>
          <p>When you change the hash distribution of a table, table data is automatically
            redistributed. Changing the distribution policy to a random distribution does not cause
            the data to be redistributed. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales SET DISTRIBUTED RANDOMLY;
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic58" xml:lang="en">
        <title>Redistributing Table Data</title>
        <body>
          <p>To redistribute table data for tables with a random distribution policy (or when the
            hash distribution policy has not changed) use <codeph>REORGANIZE=TRUE</codeph>.
            Reorganizing data may be necessary to correct a data skew problem, or when segment
            resources are added to the system. For example, the following command redistributes
            table data across all segments using the current distribution policy, including random
            distribution.</p>
          <p>
            <codeblock>ALTER TABLE sales SET WITH (REORGANIZE=TRUE);
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic59" xml:lang="en">
        <title>Altering the Table Storage Model</title>
        <body>
          <p>Table storage, compression, and orientation can be declared only at creation. To change
            the storage model, you must create a table with the correct storage options, load the
            original table data into the new table, drop the original table, and rename the new
            table with the original table's name. You must also re-grant any table permissions. For
            example:</p>
          <p>
            <codeblock>CREATE TABLE sales2 (LIKE sales) 
WITH (appendonly=true, compresstype=quicklz, 
      compresslevel=1, orientation=column);
INSERT INTO sales2 SELECT * FROM sales;
DROP TABLE sales;
ALTER TABLE sales2 RENAME TO sales;
GRANT ALL PRIVILEGES ON sales TO admin;
GRANT SELECT ON sales TO guest;
</codeblock>
          </p>
          <p>See <xref href="#topic83" type="topic" format="dita"/> to learn how to change the
            storage model of a partitioned table.</p>
        </body>
        <topic id="topic60" xml:lang="en">
          <title id="im196377">
            <b>Adding a Compressed Column to Table</b>
          </title>
          <body>
            <p>Use <codeph>ALTER TABLE</codeph> command to add a compressed column to a table. All
              of the options and constraints for compressed columns described in <xref href="#topic43" type="topic" format="dita"/> apply to columns added with the
                <codeph>ALTER TABLE</codeph> command. </p>
            <p>The following example shows how to add a column with <codeph>zlib</codeph>
              compression to a table, <codeph>T1</codeph>.</p>
            <p>
              <codeblock>ALTER TABLE T1
&#160;&#160;&#160;&#160;&#160;&#160;ADD COLUMN c4 int DEFAULT 0
&#160;&#160;&#160;&#160;&#160;&#160;ENCODING (COMPRESSTYPE=zlib);
</codeblock>
            </p>
          </body>
        </topic>
        <topic id="topic61" xml:lang="en">
          <title>
            <b>Inheritance of Compression Settings</b>
          </title>
          <body>
            <p>A partition that is added to a table that has subpartitions with compression settings
              inherits the compression settings from the subpartition.The following example shows
              how to create a table with subpartition encodings, then alter it to add a
              partition.</p>
            <p>
              <codeblock>CREATE TABLE ccddl (i int, j int, k int, l int)
&#160;&#160;WITH
&#160;&#160;&#160;&#160;(APPENDONLY = TRUE, ORIENTATION=COLUMN)
&#160;&#160;PARTITION BY range(j)
&#160;&#160;SUBPARTITION BY list (k)
&#160;&#160;SUBPARTITION template(
&#160;&#160;&#160;&#160;SUBPARTITION sp1 values(1, 2, 3, 4, 5),
&#160;&#160;&#160;&#160;COLUMN i ENCODING(COMPRESSTYPE=ZLIB),
&#160;&#160;&#160;&#160;COLUMN j ENCODING(COMPRESSTYPE=QUICKLZ),
&#160;&#160;&#160;&#160;COLUMN k ENCODING(COMPRESSTYPE=ZLIB),
&#160;&#160;&#160;&#160;COLUMN l ENCODING(COMPRESSTYPE=ZLIB))
&#160;&#160;(PARTITION p1 START(1) END(10),
&#160;&#160;&#160;PARTITION p2 START(10) END(20))
;

ALTER TABLE ccddl
&#160;&#160;ADD PARTITION p3 START(20) END(30)
;
</codeblock>
            </p>
            <p>Running the <codeph>ALTER TABLE</codeph> command creates partitions of table
                <codeph>ccddl</codeph> named <codeph>ccddl_1_prt_p3</codeph> and
                <codeph>ccddl_1_prt_p3_2_prt_sp1</codeph>. Partition <codeph>ccddl_1_prt_p3</codeph>
              inherits the different compression encodings of subpartition <codeph>sp1</codeph>.</p>
          </body>
        </topic>
      </topic>
    </topic>
    <topic id="topic62" xml:lang="en">
      <title>Dropping a Table</title>
      <body>
        <p><ph>The </ph><codeph>DROP TABLE </codeph>command removes tables from the database. For
          example:</p>
        <p>
          <codeblock>DROP TABLE mytable;
</codeblock>
        </p>
        <p>To empty a table of rows without removing the table definition, use
            <codeph>DELETE</codeph> or <codeph>TRUNCATE</codeph>. For example:</p>
        <p>
          <codeblock>DELETE FROM mytable;

TRUNCATE mytable;
</codeblock>
        </p>
        <p><codeph>DROP TABLE </codeph>always removes any indexes, rules, triggers, and constraints
          that exist for the target table. Specify <codeph>CASCADE </codeph>to drop a table that is
          referenced by a view. <codeph>CASCADE</codeph> removes dependent views. </p>
      </body>
    </topic>
  </topic>
  <topic id="topic63" xml:lang="en">
    <title id="im204286">Partitioning Large Tables</title>
    <body>
      <p>Table partitioning enables supporting very large tables, such as fact tables, by logically
        dividing them into smaller, more manageable pieces. Partitioned tables can improve query
        performance by allowing the Greenplum Database query planner to scan only the data needed to
        satisfy a given query instead of scanning all the contents of a large table. </p>
      <p>Partitioning does not change the physical distribution of table data across the segments.
        Table distribution is physical: Greenplum Database physicially divides partitioned tables
        and non-partitioned tables across segments to enable parallel query processing. Table
          <i>partitioning</i> is logical: Greenplum Database logically divides big tables to improve
        query performance and facilitate data warehouse maintenance tasks, such as rolling old data
        out of the data warehouse. </p>
      <p>Greenplum Database supports:</p>
      <ul>
        <li id="im204035"><i>range partitioning</i>: division of data based on a numerical range,
          such as date or price.</li>
        <li id="im207235"><i>list partitioning</i>: division of data based on a list of values, such
          as sales territory or product line.</li>
        <li id="im207242">A combination of both types.</li>
      </ul>
      <fig id="im207241">
        <title>Example Multi-level Partition Design</title>
        <image href="../graphics/partitions.jpg" placement="break" width="344px" height="203px"/>
      </fig>
    </body>
    <topic id="topic64" xml:lang="en">
      <title>Table Partitioning in Greenplum Database</title>
      <body>
        <p>Greenplum Database divides tables into parts (also known as partitions) to enable
          massively parallel processing. Tables are partitioned during <codeph>CREATE TABLE</codeph>
          using the <codeph>PARTITION BY</codeph> (and optionally the <codeph>SUBPARTITION
            BY</codeph>) clause. When you partition a table in Greenplum Database, you create a
          top-level (or parent) table with one or more levels of sub-tables (or child tables).
          Internally, Greenplum Database creates an inheritance relationship between the top-level
          table and its underlying partitions, similar to the functionality of the
            <codeph>INHERITS</codeph> clause of PostgreSQL.</p>
        <p>Greenplum uses the partition criteria defined during table creation to create each
          partition with a distinct <codeph>CHECK</codeph> constraint, which limits the data that
          table can contain. The query planner uses <codeph>CHECK</codeph> constraints to determine
          which table partitions to scan to satisfy a given query predicate.</p>
        <p>The Greenplum system catalog stores partition hierarchy information so that rows inserted
          into the top-level parent table propagate correctly to the child table partitions. To
          change the partition design or table structure, alter the parent table using <codeph>ALTER
            TABLE</codeph> with the <codeph>PARTITION</codeph> clause.</p>
        <p>Execution of <codeph>INSERT</codeph>, <codeph>UPDATE</codeph> and <codeph>DELETE</codeph>
          commands directly on a specific partition (child table) of a partitioned table is not
          supported. Instead, these commands must be executed on the root partitioned table, the
          table created with the <codeph>CREATE TABLE</codeph> command.</p>
      </body>
    </topic>
    <topic id="topic65" xml:lang="en">
      <title>Deciding on a Table Partitioning Strategy</title>
      <body>
        <p>Not all tables are good candidates for partitioning. If the answer is <i>yes</i> to all
          or most of the following questions, table partitioning is a viable database design
          strategy for improving query performance. If the answer is <i>no</i> to most of the
          following questions, table partitioning is not the right solution for that table. Test
          your design strategy to ensure that query performance improves as expected.</p>
        <ul>
          <li id="im148863"><b>Is the table large enough?</b> Large fact tables are good candidates
            for table partitioning. If you have millions or billions of records in a table, you will
            see performance benefits from logically breaking that data up into smaller chunks. For
            smaller tables with only a few thousand rows or less, the administrative overhead of
            maintaining the partitions will outweigh any performance benefits you might see.</li>
          <li id="im148864"><b>Are you experiencing unsatisfactory performance?</b> As with any
            performance tuning initiative, a table should be partitioned only if queries against
            that table are producing slower response times than desired. </li>
          <li id="im148865"><b>Do your query predicates have identifiable access patterns?</b>
            Examine the <codeph>WHERE</codeph> clauses of your query workload and look for table
            columns that are consistently used to access data. For example, if most of your queries
            tend to look up records by date, then a monthly or weekly date-partitioning design might
            be beneficial. Or if you tend to access records by region, consider a list-partitioning
            design to divide the table by region.</li>
          <li id="im204373"><b>Does your data warehouse maintain a window of historical data?</b>
            Another consideration for partition design is your organization's business requirements
            for maintaining historical data. For example, your data warehouse may require that you
            keep data for the past twelve months. If the data is partitioned by month, you can
            easily drop the oldest monthly partition from the warehouse and load current data into
            the most recent monthly partition.</li>
          <li id="im148867"><b>Can the data be divided into somewhat equal parts based on some
              defining criteria?</b> Choose partitioning criteria that will divide your data as
            evenly as possible. If the partitions contain a relatively equal number of records,
            query performance improves based on the number of partitions created. For example, by
            dividing a large table into 10 partitions, a query will execute 10 times faster than it
            would against the unpartitioned table, provided that the partitions are designed to
            support the query's criteria.</li>
        </ul>
      </body>
    </topic>
    <topic id="topic66" xml:lang="en">
      <title>Creating Partitioned Tables</title>
      <body>
        <p>You partition tables when you create them with <codeph>CREATE TABLE</codeph>. This topic
          provides examples of SQL syntax for creating a table with various partition designs. </p>
        <p>To partition a table:</p>
        <ol>
          <li id="im204435">Decide on the partition design: date range, numeric range, or list of
            values.</li>
          <li id="im204448">Choose the column(s) on which to partition the table. </li>
          <li id="im204455">Decide how many levels of partitions you want. For example, you can
            create a date range partition table by month and then subpartition the monthly
            partitions by sales region. </li>
        </ol>
        <ul>
          <li id="im153718">
            <xref href="#topic67" type="topic" format="dita"/>
          </li>
          <li id="im153726">
            <xref href="#topic68" type="topic" format="dita"/>
          </li>
          <li id="im153737">
            <xref href="#topic69" type="topic" format="dita"/>
          </li>
          <li id="im153742">
            <xref href="#topic70" type="topic" format="dita"/>
          </li>
          <li id="im153747">
            <xref href="#topic71" type="topic" format="dita"/>
          </li>
        </ul>
      </body>
      <topic id="topic67" xml:lang="en">
        <title id="im148871">Defining Date Range Table Partitions</title>
        <body>
          <p>A date range partitioned table uses a single <codeph>date</codeph> or
              <codeph>timestamp</codeph> column as the partition key column. You can use the same
            partition key column to create subpartitions if necessary, for example, to partition by
            month and then subpartition by day. Consider partitioning by the most granular level.
            For example, for a table partitioned by date, you can partition by day and have 365
            daily partitions, rather than partition by year then subpartition by month then
            subpartition by day. A multi-level design can reduce query planning time, but a flat
            partition design runs faster.</p>
          <p>You can have Greenplum Database automatically generate partitions by giving a
              <codeph>START</codeph> value, an <codeph>END</codeph> value, and an
              <codeph>EVERY</codeph> clause that defines the partition increment value. By default,
              <codeph>START</codeph> values are always inclusive and <codeph>END</codeph> values are
            always exclusive. For example:</p>
          <p>
            <codeblock>CREATE TABLE sales (id int, date date, amt decimal(10,2))
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
( START (date '2008-01-01') INCLUSIVE
   END (date '2009-01-01') EXCLUSIVE
   EVERY (INTERVAL '1 day') );
</codeblock>
          </p>
          <p>You can also declare and name each partition individually. For example:</p>
          <p>
            <codeblock>CREATE TABLE sales (id int, date date, amt decimal(10,2))
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
( PARTITION Jan08 START (date '2008-01-01') INCLUSIVE , 
&#160;&#160;PARTITION Feb08 START (date '2008-02-01') INCLUSIVE ,
&#160;&#160;PARTITION Mar08 START (date '2008-03-01') INCLUSIVE ,
&#160;&#160;PARTITION Apr08 START (date '2008-04-01') INCLUSIVE ,
&#160;&#160;PARTITION May08 START (date '2008-05-01') INCLUSIVE ,
&#160;&#160;PARTITION Jun08 START (date '2008-06-01') INCLUSIVE ,
&#160;&#160;PARTITION Jul08 START (date '2008-07-01') INCLUSIVE ,
&#160;&#160;PARTITION Aug08 START (date '2008-08-01') INCLUSIVE ,
&#160;&#160;PARTITION Sep08 START (date '2008-09-01') INCLUSIVE ,
&#160;&#160;PARTITION Oct08 START (date '2008-10-01') INCLUSIVE ,
&#160;&#160;PARTITION Nov08 START (date '2008-11-01') INCLUSIVE ,
&#160;&#160;PARTITION Dec08 START (date '2008-12-01') INCLUSIVE 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;END (date '2009-01-01') EXCLUSIVE );
</codeblock>
          </p>
          <p>You do not have to declare an <codeph>END</codeph> value for each partition, only the
            last one. In this example, <codeph>Jan08</codeph> ends where <codeph>Feb08</codeph>
            starts.</p>
        </body>
      </topic>
      <topic id="topic68" xml:lang="en">
        <title id="im172582">Defining Numeric Range Table Partitions</title>
        <body>
          <p>A numeric range partitioned table uses a single numeric data type column as the
            partition key column. For example:</p>
          <p>
            <codeblock>CREATE TABLE rank (id int, rank int, year int, gender 
char(1), count int)
DISTRIBUTED BY (id)
PARTITION BY RANGE (year)
( START (2001) END (2008) EVERY (1), 
&#160;&#160;DEFAULT PARTITION extra ); 
</codeblock>
          </p>
          <p>For more information about default partitions, see <xref href="#topic80" type="topic" format="dita"/>.</p>
        </body>
      </topic>
      <topic id="topic69" xml:lang="en">
        <title id="im148873">Defining List Table Partitions</title>
        <body>
          <p>A list partitioned table can use any data type column that allows equality comparisons
            as its partition key column. A list partition can also have a multi-column (composite)
            partition key, whereas a range partition only allows a single column as the partition
            key. For list partitions, you must declare a partition specification for every partition
            (list value) you want to create. For example:</p>
          <p>
            <codeblock>CREATE TABLE rank (id int, rank int, year int, gender 
char(1), count int ) 
DISTRIBUTED BY (id)
PARTITION BY LIST (gender)
( PARTITION girls VALUES ('F'), 
  PARTITION boys VALUES ('M'), 
&#160;&#160;DEFAULT PARTITION other );
</codeblock>
          </p>
          <p>For more information about default partitions, see <xref href="#topic80" type="topic" format="dita"/>.</p>
        </body>
      </topic>
      <topic id="topic70" xml:lang="en">
        <title id="im148875">Defining Multi-level Partitions</title>
        <body>
          <p>You can create a multi-level partition design with subpartitions of partitions. Using a
              <i>subpartition template</i> ensures that every partition has the same subpartition
            design, including partitions that you add later. For example, the following SQL creates
            the two-level partition design shown in <xref href="#topic63/im207241" type="fig" format="dita"/>:</p>
          <p>
            <codeblock>CREATE TABLE sales (trans_id int, date date, amount 
decimal(9,2), region text) 
DISTRIBUTED BY (trans_id)
PARTITION BY RANGE (date)
SUBPARTITION BY LIST (region)
SUBPARTITION TEMPLATE
( SUBPARTITION usa VALUES ('usa'), 
&#160;&#160;SUBPARTITION asia VALUES ('asia'), 
&#160;&#160;SUBPARTITION europe VALUES ('europe'), 
&#160;&#160;DEFAULT SUBPARTITION other_regions)
&#160;&#160;(START (date '2011-01-01') INCLUSIVE
&#160;&#160;END (date '2012-01-01') EXCLUSIVE
&#160;&#160;EVERY (INTERVAL '1 month'), 
&#160;&#160;DEFAULT PARTITION outlying_dates );
</codeblock>
          </p>
          <p>The following example shows a three-level partition design where the
              <codeph>sales</codeph> table is partitioned by <codeph>year</codeph>, then
              <codeph>month</codeph>, then <codeph>region</codeph>. The <codeph>SUBPARTITION
              TEMPLATE</codeph> clauses ensure that each yearly partition has the same subpartition
            structure. The example declares a <codeph>DEFAULT</codeph> partition at each level of
            the hierarchy.</p>
          <p>
            <codeblock>CREATE TABLE p3_sales (id int, year int, month int, day int, 
region text)
DISTRIBUTED BY (id)
PARTITION BY RANGE (year)
&#160;&#160;&#160;&#160;SUBPARTITION BY RANGE (month)
&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION TEMPLATE (
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;START (1) END (13) EVERY (1), 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DEFAULT SUBPARTITION other_months )
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION BY LIST (region)
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION TEMPLATE (
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION usa VALUES ('usa'),
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION europe VALUES ('europe'),
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION asia VALUES ('asia'),
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DEFAULT SUBPARTITION other_regions )
( START (2002) END (2012) EVERY (1), 
&#160;&#160;DEFAULT PARTITION outlying_years );
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic71" xml:lang="en">
        <title id="im162902">Partitioning an Existing Table</title>
        <body>
          <p>Tables can be partitioned only at creation. If you have a table that you want to
            partition, you must create a partitioned table, load the data from the original table
            into the new table, drop the original table, and rename the partitioned table with the
            original table's name. You must also re-grant any table permissions. For example:</p>
          <p>
            <codeblock>CREATE TABLE sales2 (LIKE sales) 
PARTITION BY RANGE (date)
( START (date '2008-01-01') INCLUSIVE
   END (date '2009-01-01') EXCLUSIVE
   EVERY (INTERVAL '1 month') );
INSERT INTO sales2 SELECT * FROM sales;
DROP TABLE sales;
ALTER TABLE sales2 RENAME TO sales;
GRANT ALL PRIVILEGES ON sales TO admin;
GRANT SELECT ON sales TO guest;
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic72" xml:lang="en">
        <title>Limitations of Partitioned Tables</title>
        <body>
          <p>A primary key or unique constraint on a partitioned table must contain all the
            partitioning columns. A unique index can omit the partitioning columns; however, it is
            enforced only on the parts of the partitioned table, not on the partitioned table as a
            whole.</p>
        </body>
      </topic>
    </topic>
    <topic id="topic73" xml:lang="en">
      <title>Loading Partitioned Tables</title>
      <body>
        <p>After you create the partitioned table structure, top-level parent tables are empty. Data
          is routed to the bottom-level child table partitions. In a multi-level partition design,
          only the subpartitions at the bottom of the hierarchy can contain data.</p>
        <p>Rows that cannot be mapped to a child table partition are rejected and the load fails. To
          avoid unmapped rows being rejected at load time, define your partition hierarchy with a
            <codeph>DEFAULT</codeph> partition. Any rows that do not match a partition's
            <codeph>CHECK</codeph> constraints load into the <codeph>DEFAULT</codeph> partition. See
            <xref href="#topic80" type="topic" format="dita"/>.</p>
        <p>At runtime, the query planner scans the entire table inheritance hierarchy and uses the
            <codeph>CHECK</codeph> table constraints to determine which of the child table
          partitions to scan to satisfy the query's conditions. The <codeph>DEFAULT</codeph>
          partition (if your hierarchy has one) is always scanned. <codeph>DEFAULT</codeph>
          partitions that contain data slow down the overall scan time.</p>
        <p>When you use <codeph>COPY</codeph> or <codeph>INSERT</codeph> to load data into a parent
          table, the data is automatically rerouted to the correct partition, just like a regular
          table. </p>
        <p>Best practice for loading data into partitioned tables is to create an intermediate
          staging table, load it, and then exchange it into your partition design. See <xref href="#topic83" type="topic" format="dita"/>.</p>
      </body>
    </topic>
    <topic id="topic74" xml:lang="en">
      <title id="im148883">Verifying Your Partition Strategy</title>
      <body>
        <p>When a table is partitioned based on the query predicate, you can use
            <codeph>EXPLAIN</codeph> to verify that the query planner scans only the relevant data
          to examine the query plan.</p>
        <p>For example, suppose a <i>sales</i> table is date-range partitioned by month and
          subpartitioned by region as shown in <xref href="#topic63/im207241" type="fig" format="dita"/>. For the following query:</p>
        <p>
          <codeblock>EXPLAIN SELECT * FROM sales WHERE date='01-07-12' AND 
region='usa';
</codeblock>
        </p>
        <p>The query plan for this query should show a table scan of only the following tables:</p>
        <ul>
          <li id="im152925">the default partition returning 0-1 rows (if your partition design has
            one)</li>
          <li id="im148892">the January 2012 partition (<i>sales_1_prt_1</i>) returning 0-1 rows </li>
          <li id="im148893">the USA region subpartition (<i>sales_1_2_prt_usa</i>) returning <i>some
              number</i> of rows. </li>
        </ul>
        <p>The following example shows the relevant portion of the query plan.</p>
        <p>
          <codeblock>-&gt;  <codeph>Seq Scan on</codeph><codeph>sales_1_prt_1</codeph> sales (cost=0.00..0.00 <codeph>rows=0</codeph> 
&#160;&#160;&#160;&#160;&#160;width=0)
Filter: "date"=01-07-08::date AND region='USA'::text
-&gt;  <codeph>Seq Scan on</codeph><codeph>sales_1_2_prt_usa</codeph> sales (cost=0.00..9.87 
<codeph>rows=20</codeph> 
&#160;&#160;&#160;&#160;&#160;&#160;width=40)
</codeblock>
        </p>
        <p>Ensure that the query planner does not scan unnecessary partitions or subpartitions (for
          example, scans of months or regions not specified in the query predicate), and that scans
          of the top-level tables return 0-1 rows. </p>
      </body>
      <topic id="topic75" xml:lang="en">
        <title>Troubleshooting Selective Partition Scanning</title>
        <body>
          <p>The following limitations can result in a query plan that shows a non-selective scan of
            your partition hierarchy.</p>
          <ul>
            <li id="im148903">The query planner can selectively scan partitioned tables only when
              the query contains a direct and simple restriction of the table using immutable
              operators such as:<p> =, &lt; , &lt;=&#160;, &gt;,&#160;&#160;&gt;=&#160;, and &lt;&gt;</p></li>
            <li id="im183866">Selective scanning recognizes <codeph>STABLE</codeph> and
                <codeph>IMMUTABLE</codeph> functions, but does not recognize
                <codeph>VOLATILE</codeph> functions within a query. For example,
                <codeph>WHERE</codeph> clauses such as <codeph>date &gt; CURRENT_DATE</codeph> cause
              the query planner to selectively scan partitioned tables, but <codeph>time &gt;
                TIMEOFDAY</codeph> does not.</li>
          </ul>
        </body>
      </topic>
    </topic>
    <topic id="topic76" xml:lang="en">
      <title>Viewing Your Partition Design</title>
      <body>
        <p>You can look up information about your partition design using the <i>pg_partitions</i>
          view. For example, to see the partition design of the <i>sales</i> table:</p>
        <p>
          <codeblock>SELECT partitionboundary, partitiontablename, partitionname, 
partitionlevel, partitionrank 
FROM pg_partitions 
WHERE tablename='sales';
</codeblock>
        </p>
        <p>The following table and views show information about partitioned tables.</p>
        <ul>
          <li id="im211944"><i>pg_partition </i>- Tracks partitioned tables and their inheritance
            level relationships. </li>
          <li id="im156096"><i>pg_partition_templates</i> - Shows the subpartitions created using a
            subpartition template.</li>
          <li id="im156103"><i>pg_partition_columns</i> - Shows the partition key columns used in a
            partition design.</li>
        </ul>
        <p>For information about Greenplum Database system catalog tables and views, see the
            <i>Greenplum Database Reference Guide</i>. </p>
      </body>
    </topic>
    <topic id="topic77" xml:lang="en">
      <title id="im154268">Maintaining Partitioned Tables</title>
      <body>
        <p>To maintain a partitioned table, use the <codeph>ALTER TABLE</codeph> command against the
          top-level parent table. The most common scenario is to drop old partitions and add new
          ones to maintain a rolling window of data in a range partition design. You can convert
            (<i>exchange</i>) older partitions to the append-optimized compressed storage format to
          save space. If you have a default partition in your partition design, you add a partition
          by <i>splitting</i> the default partition.</p>
        <ul>
          <li id="im154171">
            <xref href="#topic78" type="topic" format="dita"/>
          </li>
          <li id="im153528">
            <xref href="#topic79" type="topic" format="dita"/>
          </li>
          <li id="im153533">
            <xref href="#topic80" type="topic" format="dita"/>
          </li>
          <li id="im153537">
            <xref href="#topic81" type="topic" format="dita"/>
          </li>
          <li id="im153550">
            <xref href="#topic82" type="topic" format="dita"/>
          </li>
          <li id="im153555">
            <xref href="#topic83" type="topic" format="dita"/>
          </li>
          <li id="im153559">
            <xref href="#topic84" type="topic" format="dita"/>
          </li>
          <li id="im163231">
            <xref href="#topic85" type="topic" format="dita"/>
          </li>
        </ul>
        <note type="important">When defining and altering partition designs, use the given partition
          name, not the table object name. Although you can query and load any table (including
          partitioned tables) directly using SQL commands, you can only modify the structure of a
          partitioned table using the <codeph>ALTER TABLE...PARTITION</codeph> clauses.<p>Partitions
            are not required to have names. If a partition does not have a name, use one of the
            following expressions to specify a part: <codeph>PARTITION FOR (value)</codeph> or
              )<codeph>PARTITION FOR(RANK(number)</codeph>.</p></note>
      </body>
      <topic id="topic78" xml:lang="en">
        <title id="im172625">Adding a Partition</title>
        <body>
          <p>You can add a partition to a partition design with the <codeph>ALTER TABLE</codeph>
            command. If the original partition design included subpartitions defined by a
              <i>subpartition template</i>, the newly added partition is subpartitioned according to
            that template. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales ADD PARTITION 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;START (date '2009-02-01') INCLUSIVE 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;END (date '2009-03-01') EXCLUSIVE;
</codeblock>
          </p>
          <p>If you did not use a subpartition template when you created the table, you define
            subpartitions when adding a partition:</p>
          <p>
            <codeblock>ALTER TABLE sales ADD PARTITION 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;START (date '2009-02-01') INCLUSIVE 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;END (date '2009-03-01') EXCLUSIVE
&#160;&#160;&#160;&#160;&#160;&#160;( SUBPARTITION usa VALUES ('usa'), 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION asia VALUES ('asia'), 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUBPARTITION europe VALUES ('europe') );
</codeblock>
          </p>
          <p>When you add a subpartition to an existing partition, you can specify the partition to
            alter. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales ALTER PARTITION FOR (RANK(12))
&#160;&#160;&#160;&#160;&#160;&#160;ADD PARTITION africa VALUES ('africa');
</codeblock>
          </p>
          <note type="note">You cannot add a partition to a partition design that has a default
            partition. You must split the default partition to add a partition. See <xref href="#topic84" type="topic" format="dita"/>.</note>
        </body>
      </topic>
      <topic id="topic79" xml:lang="en">
        <title id="im153493">Renaming a Partition</title>
        <body>
          <p>Partitioned tables use the following naming convention. Partitioned subtable names are
            subject to uniqueness requirements and length limitations. </p>
          <p>
            <codeblock><i>&lt;parentname&gt;</i>_<i>&lt;level&gt;</i>_prt_<i>&lt;partition_name&gt;</i></codeblock>
          </p>
          <p>For example:</p>
          <p>
            <codeblock><i>sales_1_prt_jan08</i></codeblock>
          </p>
          <p>For auto-generated range partitions, where a number is assigned when no name is
            given):</p>
          <p>
            <codeblock><i>sales_1_prt_1</i></codeblock>
          </p>
          <p>To rename a partitioned child table, rename the top-level parent table. The
              <i>&lt;parentname&gt;</i> changes in the table names of all associated child table
            partitions. For example, the following command:</p>
          <p>
            <codeblock>ALTER TABLE sales RENAME TO globalsales;
</codeblock>
          </p>
          <p>Changes the associated table names:</p>
          <p>
            <codeblock><i>globalsales_1_prt_1</i></codeblock>
          </p>
          <p>You can change the name of a partition to make it easier to identify. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales RENAME PARTITION FOR ('2008-01-01') TO jan08;
</codeblock>
          </p>
          <p>Changes the associated table name as follows:</p>
          <p>
            <codeblock><i>sales_1_prt_jan08</i></codeblock>
          </p>
          <p>When altering partitioned tables with the <codeph>ALTER TABLE</codeph> command, always
            refer to the tables by their partition name (<i>jan08</i>) and not their full table name
              (<i>sales_1_prt_jan08</i>).</p>
          <note type="note">The table name cannot be a partition name in an <codeph>ALTER
              TABLE</codeph> statement. For example, <codeph>ALTER TABLE sales...</codeph> is
            correct, <codeph>ALTER TABLE sales_1_part_jan08...</codeph> is not allowed.</note>
        </body>
      </topic>
      <topic id="topic80" xml:lang="en">
        <title id="im152983">Adding a Default Partition</title>
        <body>
          <p>You can add a default partition to a partition design with the <codeph>ALTER
              TABLE</codeph> command. </p>
          <p>
            <codeblock>ALTER TABLE sales ADD DEFAULT PARTITION other;
</codeblock>
          </p>
          <p>If your partition design is multi-level, each level in the hierarchy must have a
            default partition. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales ALTER PARTITION FOR (RANK(1)) ADD DEFAULT 
PARTITION other;

ALTER TABLE sales ALTER PARTITION FOR (RANK(2)) ADD DEFAULT 
PARTITION other;

ALTER TABLE sales ALTER PARTITION FOR (RANK(3)) ADD DEFAULT 
PARTITION other;
</codeblock>
          </p>
          <p>If incoming data does not match a partition's <codeph>CHECK</codeph> constraint and
            there is no default partition, the data is rejected. Default partitions ensure that
            incoming data that does not match a partition is inserted into the default
            partition.</p>
        </body>
      </topic>
      <topic id="topic81" xml:lang="en">
        <title id="im148907">Dropping a Partition</title>
        <body>
          <p>You can drop a partition from your partition design using the <codeph>ALTER
              TABLE</codeph> command. When you drop a partition that has subpartitions, the
            subpartitions (and all data in them) are automatically dropped as well. For range
            partitions, it is common to drop the older partitions from the range as old data is
            rolled out of the data warehouse. For example:</p>
          <p>
            <codeblock>ALTER TABLE sales DROP PARTITION FOR (RANK(1));
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic82" xml:lang="en">
        <title id="im164130">Truncating a Partition</title>
        <body>
          <p>You can truncate a partition using the <codeph>ALTER TABLE</codeph> command. When you
            truncate a partition that has subpartitions, the subpartitions are automatically
            truncated as well. </p>
          <p>
            <codeblock>ALTER TABLE sales TRUNCATE PARTITION FOR (RANK(1));
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic83" xml:lang="en">
        <title id="im148982">Exchanging a Partition</title>
        <body>
          <p>You can exchange a partition using the <codeph>ALTER TABLE</codeph> command. Exchanging
            a partition swaps one table in place of an existing partition. You can exchange
            partitions only at the lowest level of your partition hierarchy (only partitions that
            contain data can be exchanged). </p>
          <p>Partition exchange can be useful for data loading. For example, load a staging table
            and swap the loaded table into your partition design. You can use partition exchange to
            change the storage type of older partitions to append-optimized tables. For example:</p>
          <p>
            <codeblock>CREATE TABLE jan12 (LIKE sales) WITH (appendonly=true);
INSERT INTO jan12 SELECT * FROM sales_1_prt_1 ;
ALTER TABLE sales EXCHANGE PARTITION FOR (DATE '2012-01-01') 
WITH TABLE jan12;
</codeblock>
          </p>
          <note type="note">This example refers to the single-level definition of the table
              <codeph>sales</codeph>, before partitions were added and altered in the previous
            examples.</note>
        </body>
      </topic>
      <topic id="topic84" xml:lang="en">
        <title id="im153485">Splitting a Partition</title>
        <body>
          <p>Splitting a partition divides a partition into two partitions. You can split a
            partition using the <codeph>ALTER TABLE</codeph> command. You can split partitions only
            at the lowest level of your partition hierarchy: only partitions that contain data can
            be split. The split value you specify goes into the <i>latter</i> partition. </p>
          <p>For example, to split a monthly partition into two with the first partition containing
            dates January 1-15 and the second partition containing dates January 16-31:</p>
          <p>
            <codeblock>ALTER TABLE sales SPLIT PARTITION FOR ('2008-01-01')
AT ('2008-01-16')
INTO (PARTITION jan081to15, PARTITION jan0816to31);
</codeblock>
          </p>
          <p>If your partition design has a default partition, you must split the default partition
            to add a partition.</p>
          <p>When using the <codeph>INTO</codeph> clause, specify the current default partition as
            the second partition name. For example, to split a default range partition to add a new
            monthly partition for January 2009:</p>
          <p>
            <codeblock>ALTER TABLE sales SPLIT DEFAULT PARTITION 
START ('2009-01-01') INCLUSIVE 
END ('2009-02-01') EXCLUSIVE 
INTO (PARTITION jan09, default partition);
</codeblock>
          </p>
        </body>
      </topic>
      <topic id="topic85" xml:lang="en">
        <title id="im163198">Modifying a Subpartition Template</title>
        <body>
          <p>Use <codeph>ALTER TABLE</codeph> SET SUBPARTITION TEMPLATE to modify the subpartition
            template for an existing partition. Partitions added after you set a new subpartition
            template have the new partition design. Existing partitions are not modified. </p>
          <p>For example, to modify the subpartition design shown in <xref href="#topic63/im207241" type="fig" format="dita"/>:</p>
          <p>
            <codeblock>ALTER TABLE sales SET SUBPARTITION TEMPLATE
( SUBPARTITION usa VALUES ('usa'), 
&#160;&#160;SUBPARTITION asia VALUES ('asia'), 
&#160;&#160;SUBPARTITION europe VALUES ('europe'),
&#160;&#160;SUBPARTITION africa VALUES ('africa')
&#160;&#160;DEFAULT SUBPARTITION other );
</codeblock>
          </p>
          <p>When you add a date-range partition of the table sales, it includes the new regional
            list subpartition for Africa. For example, the following command creates the
            subpartitions <codeph>usa</codeph>, <codeph>asia</codeph>, <codeph>europe</codeph>,
              <codeph>africa</codeph>, and a default partition named <codeph>other</codeph>:</p>
          <p>
            <codeblock>ALTER TABLE sales ADD PARTITION sales_prt_3
&#160;&#160;START ('2009-03-01') INCLUSIVE 
&#160;&#160;END ('2009-04-01') EXCLUSIVE );
</codeblock>
          </p>
          <p>To remove a subpartition template, use <codeph>SET SUBPARTITION TEMPLATE</codeph> with
            empty parentheses. For example, to clear the sales table subpartition template:</p>
          <p>
            <codeblock>ALTER TABLE sales SET SUBPARTITION TEMPLATE ();
</codeblock>
          </p>
        </body>
      </topic>
    </topic>
  </topic>
  <topic id="topic86" xml:lang="en">
    <title id="im148803">Creating and Using Sequences</title>
    <body>
      <p>You can use sequences to auto-increment unique ID columns of a table whenever a record is
        added. Sequences are often used to assign unique identification numbers to rows added to a
        table. You can declare an identifier column of type <codeph>SERIAL</codeph> to implicitly
        create a sequence for use with a column.</p>
    </body>
    <topic id="topic87" xml:lang="en">
      <title>Creating a Sequence</title>
      <body>
        <p>The <codeph>CREATE SEQUENCE </codeph>command creates and initializes a special single-row
          sequence generator table with the given sequence name. The sequence name must be distinct
          from the name of any other sequence, table, index, or view in the same schema. For
          example:</p>
        <p>
          <codeblock>CREATE SEQUENCE myserial START 101;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic88" xml:lang="en">
      <title>Using a Sequence</title>
      <body>
        <p>After you create a sequence generator table using <codeph>CREATE SEQUENCE</codeph>, you
          can use the <codeph>nextval</codeph> function to operate on the sequence. For example, to
          insert a row into a table that gets the next value of a sequence:</p>
        <p>
          <codeblock>INSERT INTO vendors VALUES (nextval('myserial'), 'acme');
</codeblock>
        </p>
        <p>You can also use the <codeph>setval</codeph> function to reset a sequence's counter
          value. For example:</p>
        <p>
          <codeblock>SELECT setval('myserial', 201);
</codeblock>
        </p>
        <p>A <codeph>nextval</codeph> operation is never rolled back. Afetched value is considered
          used, even if the transaction that performed the <codeph>nextval</codeph> fails. This
          means that failed transactions can leave unused holes in the sequence of assigned values.
            <codeph>setval</codeph> operations are never rolled back. </p>
        <p>Note that the <codeph>nextval</codeph> function is not allowed in <codeph>UPDATE</codeph>
          or <codeph>DELETE</codeph> statements if mirroring is enabled, and the
            <codeph>currval</codeph> and <codeph>lastval</codeph> functions are not supported in
          Greenplum Database.</p>
        <p>To examine the current settings of a sequence, query the sequence table:</p>
        <p>
          <codeblock>SELECT * FROM myserial;
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic89" xml:lang="en">
      <title>Altering a Sequence</title>
      <body>
        <p>The <codeph>ALTER SEQUENCE</codeph> command changes the parameters of an existing
          sequence generator. For example:</p>
        <p>
          <codeblock>ALTER SEQUENCE myserial RESTART WITH 105;
</codeblock>
        </p>
        <p>Any parameters not set in the <codeph>ALTER SEQUENCE</codeph> command retain their prior
          settings.</p>
      </body>
    </topic>
    <topic id="topic90" xml:lang="en">
      <title>Dropping a Sequence</title>
      <body>
        <p>The <codeph>DROP SEQUENCE</codeph> command removes a sequence generator table. For
          example:</p>
        <p>
          <codeblock>DROP SEQUENCE myserial;
</codeblock>
        </p>
      </body>
    </topic>
  </topic>
  <topic id="topic91" xml:lang="en">
    <title id="im143866">Using Indexes in Greenplum Database</title>
    <body>
      <p>In most traditional databases, indexes can greatly improve data access times. However, in a
        distributed database such as Greenplum, indexes should be used more sparingly. Greenplum
        Database performs very fast sequential scans; indexes use a random seek pattern to locate
        records on disk. Greenplum data is distributed across the segments, so each segment scans a
        smaller portion of the overall data to get the result. With table partitioning, the total
        data to scan may be even smaller. Because business intelligence (BI) query workloads
        generally return very large data sets, using indexes is not efficient.</p>
      <p>Greenplum recommends trying your query workload without adding indexes. Indexes are more
        likely to improve performance for OLTP workloads, where the query is returning a single
        record or a small subset of data. Indexes can also improve performance on compressed
        append-optimized tables for queries that return a targeted set of rows, as the optimizer can
        use an index access method rather than a full table scan when appropriate. For compressed
        data, an index access method means only the necessary rows are uncompressed. </p>
      <p>Greenplum Database automatically creates <codeph>PRIMARY KEY</codeph> constraints for
        tables with primary keys. To create an index on a partitioned table, index each partitioned
        child table. Indexes on the parent table do not apply to child table partitions.</p>
      <p>To create an index on a partitioned table, create an index on the partitioned table that
        you create. The index is propagated to all the child tables created by Greenplum Database.
        Creating an index on a table that is created by Greenplum Database for use by a partitioned
        table is not supported. </p>
      <p>Note that a <codeph>UNIQUE CONSTRAINT</codeph> (such as a <codeph>PRIMARY KEY
          CONSTRAINT</codeph>) implicitly creates a <codeph>UNIQUE INDEX</codeph> that must include
        all the columns of the distribution key and any partitioning key. The <codeph>UNIQUE
          CONSTRAINT</codeph> is enforced across the entire table, including all table partitions
        (if any).</p>
      <p>Indexes add some database overhead &#8212; they use storage space and must be maintained when the
        table is updated. Ensure that the query workload uses the indexes that you create, and check
        that the indexes you add improve query performance (as compared to a sequential scan of the
        table). To determine whether indexes are being used, examine the query
          <codeph>EXPLAIN</codeph> plans. See <xref href="query.xml#topic39" type="topic" format="dita"/>.</p>
      <p>Consider the following points when you create indexes.</p>
      <ul>
        <li id="im151751"><b>Your Query Workload.</b> Indexes improve performance for workloads
          where queries return a single record or a very small data set, such as OLTP
          workloads.</li>
        <li id="im174599">Compressed Tables. Indexes can improve performance on compressed
          append-optimized tables for queries that return a targeted set of rows. For compressed
          data, an index access method means only the necessary rows are uncompressed.</li>
        <li id="im151752"><b>Avoid indexes on frequently updated columns.</b> Creating an index on a
          column that is frequently updated increases the number of writes required when the column
          is updated.</li>
        <li id="im151753"><b>Create selective B-tree indexes.</b> Index selectivity is a ratio of
          the number of distinct values a column has divided by the number of rows in a table. For
          example, if a table has 1000 rows and a column has 800 distinct values, the selectivity of
          the index is 0.8, which is considered good. Unique indexes always have a selectivity ratio
          of 1.0, which is the best possible. Greenplum Database allows unique indexes only on
          distribution key columns.</li>
        <li id="im151760"><b>Use Bitmap indexes for low selectivity columns. </b>The Greenplum
          Database Bitmap index type is not available in regular PostgreSQL. See <xref href="#topic93" type="topic" format="dita"/>.</li>
        <li id="im151764"><b>Index columns used in joins.</b> An index on a column used for frequent
          joins (such as a foreign key column) can improve join performance by enabling more join
          methods for the query planner to use.</li>
        <li id="im151765"><b>Index columns frequently used in predicates.</b> Columns that are
          frequently referenced in <codeph>WHERE</codeph> clauses are good candidates for
          indexes.</li>
        <li id="im151766"><b>Avoid overlapping indexes.</b> Indexes that have the same leading
          column are redundant.</li>
        <li id="im151767"><b>Drop indexes for bulk loads.</b> For mass loads of data into a table,
          consider dropping the indexes and re-creating them after the load completes. This is often
          faster than updating the indexes. </li>
        <li id="im151768"><b>Consider a clustered index.</b> Clustering an index means that the
          records are physically ordered on disk according to the index. If the records you need are
          distributed randomly on disk, the database has to seek across the disk to fetch the
          records requested. If the records are stored close together, the fetching operation is
          more efficient. For example, a clustered index on a date column where the data is ordered
          sequentially by date. A query against a specific date range results in an ordered fetch
          from the disk, which leverages fast sequential access.</li>
      </ul>
      <section id="im151772">
        <title>To cluster an index in Greenplum Database</title>
        <p>Using the <codeph>CLUSTER</codeph> command to physically reorder a table based on an
          index can take a long time with very large tables. To achieve the same results much
          faster, you can manually reorder the data on disk by creating an intermediate table and
          loading the data in the desired order. For example:</p>
        <p>
          <codeblock>CREATE TABLE new_table (LIKE old_table) 
&#160;&#160;&#160;&#160;&#160;&#160;&#160;AS SELECT * FROM old_table ORDER BY myixcolumn;
DROP old_table;
ALTER TABLE new_table RENAME TO old_table;
CREATE INDEX myixcolumn_ix ON old_table;
VACUUM ANALYZE old_table;
</codeblock>
        </p>
      </section>
    </body>
    <topic id="topic92" xml:lang="en">
      <title>Index Types</title>
      <body>
        <p>Greenplum Database supports the Postgres index types B-tree and GiST. Hash and GIN
          indexes are not supported. Each index type uses a different algorithm that is best suited
          to different types of queries. B-tree indexes fit the most common situations and are the
          default index type. See <xref href="https://www.postgresql.org/docs/8.3/static/indexes-types.html" scope="external" format="html"><ph>Index Types</ph></xref> in the PostgreSQL documentation for a
          description of these types.</p>
        <note type="note">Greenplum Database allows unique indexes only if the columns of the index
          key are the same as (or a superset of) the Greenplum distribution key. Unique indexes are
          not supported on append-optimized tables. On partitioned tables, a unique index cannot be
          enforced across all child table partitions of a partitioned table. A unique index is
          supported only within a partition.</note>
      </body>
      <topic id="topic93" xml:lang="en">
        <title id="im143283">About Bitmap Indexes</title>
        <body>
          <p>Greenplum Database provides the Bitmap index type. Bitmap indexes are best suited to
            data warehousing applications and decision support systems with large amounts of data,
            many ad hoc queries, and few data modification (DML) transactions.</p>
          <p>An index provides pointers to the rows in a table that contain a given key value. A
            regular index stores a list of tuple IDs for each key corresponding to the rows with
            that key value. Bitmap indexes store a bitmap for each key value. Regular indexes can be
            several times larger than the data in the table, but bitmap indexes provide the same
            functionality as a regular index and use a fraction of the size of the indexed data.</p>
          <p>Each bit in the bitmap corresponds to a possible tuple ID. If the bit is set, the row
            with the corresponding tuple ID contains the key value. A mapping function converts the
            bit position to a tuple ID. Bitmaps are compressed for storage. If the number of
            distinct key values is small, bitmap indexes are much smaller, compress better, and save
            considerable space compared with a regular index. The size of a bitmap index is
            proportional to the number of rows in the table times the number of distinct values in
            the indexed column.</p>
          <p>Bitmap indexes are most effective for queries that contain multiple conditions in the
              <codeph>WHERE</codeph> clause. Rows that satisfy some, but not all, conditions are
            filtered out before the table is accessed. This improves response time, often
            dramatically.</p>
        </body>
        <topic id="topic94" xml:lang="en">
          <title>When to Use Bitmap Indexes</title>
          <body>
            <p>Bitmap indexes are best suited to data warehousing applications where users query the
              data rather than update it. Bitmap indexes perform best for columns that have between
              100 and 100,000 distinct values and when the indexed column is often queried in
              conjunction with other indexed columns. Columns with fewer than 100 distinct values,
              such as a gender column with two distinct values (male and female), usually do not
              benefit much from any type of index. On a column with more than 100,000 distinct
              values, the performance and space efficiency of a bitmap index decline. </p>
            <p>Bitmap indexes can improve query performance for ad hoc queries. <codeph>AND</codeph>
              and <codeph>OR</codeph> conditions in the <codeph>WHERE</codeph> clause of a query can
              be resolved quickly by performing the corresponding Boolean operations directly on the
              bitmaps before converting the resulting bitmap to tuple ids. If the resulting number
              of rows is small, the query can be answered quickly without resorting to a full table
              scan.</p>
          </body>
        </topic>
        <topic id="topic95" xml:lang="en">
          <title>When Not to Use Bitmap Indexes</title>
          <body>
            <p>Do not use bitmap indexes for unique columns or columns with high cardinality data,
              such as customer names or phone numbers. The performance gains and disk space
              advantages of bitmap indexes start to diminish on columns with 100,000 or more unique
              values, regardless of the number of rows in the table.</p>
            <p>Bitmap indexes are not suitable for OLTP applications with large numbers of
              concurrent transactions modifying the data.</p>
            <p>Use bitmap indexes sparingly. Test and compare query performance with and without an
              index. Add an index only if query performance improves with indexed columns.</p>
          </body>
        </topic>
      </topic>
    </topic>
    <topic id="topic96" xml:lang="en">
      <title>Creating an Index</title>
      <body>
        <p>The <codeph>CREATE INDEX</codeph> command defines an index on a table. A B-tree index is
          the default index type. For example, to create a B-tree index on the column <i>gender</i>
          in the table <i>employee</i>:</p>
        <p>
          <codeblock>CREATE INDEX gender_idx ON employee (gender);
</codeblock>
        </p>
        <p>To create a bitmap index on the column <i>title</i> in the table <i>films</i>:</p>
        <p>
          <codeblock>CREATE INDEX title_bmp_idx ON films USING bitmap (title);
</codeblock>
        </p>
      </body>
    </topic>
    <topic id="topic97" xml:lang="en">
      <title>Examining Index Usage</title>
      <body>
        <p>Greenplum Database indexes do not require maintenance and tuning. You can check which
          indexes are used by the real-life query workload. Use the <codeph>EXPLAIN</codeph> command
          to examine index usage for a query.</p>
        <p>The query plan shows the steps or <i>plan nodes</i> that the database will take to answer
          a query and time estimates for each plan node. To examine the use of indexes, look for the
          following query plan node types in your <codeph>EXPLAIN</codeph> output:</p>
        <ul>
          <li id="im143464"><b>Index Scan</b> - A scan of an index.</li>
          <li id="im143465"><b>Bitmap Heap Scan</b> - Retrieves all </li>
          <li id="im207555">from the bitmap generated by BitmapAnd, BitmapOr, or BitmapIndexScan and
            accesses the heap to retrieve the relevant rows.</li>
          <li id="im143466"><b>Bitmap Index Scan</b> - Compute a bitmap by OR-ing all bitmaps that
            satisfy the query predicates from the underlying index.</li>
          <li id="im143467"><b>BitmapAnd</b> or <b>BitmapOr</b> - Takes the bitmaps generated from
            multiple BitmapIndexScan nodes, ANDs or ORs them together, and generates a new bitmap as
            its output.</li>
        </ul>
        <p>You have to experiment to determine the indexes to create. Consider the following
          points.</p>
        <ul>
          <li id="im143930">Run <codeph>ANALYZE</codeph> after you create or update an index.
              <codeph>ANALYZE</codeph> collects table statistics. The query planner uses table
            statistics to estimate the number of rows returned by a query and to assign realistic
            costs to each possible query plan.</li>
          <li id="im143932">Use real data for experimentation. Using test data for setting up
            indexes tells you what indexes you need for the test data, but that is all. </li>
          <li id="im143934">Do not use very small test data sets as the results can be unrealistic
            or skewed. </li>
          <li id="im205776">Be careful when developing test data. Values that are similar,
            completely random, or inserted in sorted order will skew the statistics away from the
            distribution that real data would have. </li>
          <li id="im144062">You can force the use of indexes for testing purposes by using run-time
            parameters to turn off specific plan types. For example, turn off sequential scans
              (<codeph>enable_seqscan</codeph>) and nested-loop joins
              (<codeph>enable_nestloop</codeph>), the most basic plans, to force the system to use a
            different plan. Time your query with and without indexes and use the <codeph>EXPLAIN
              ANALYZE</codeph> command to compare the results.</li>
        </ul>
      </body>
    </topic>
    <topic id="topic98" xml:lang="en">
      <title>Managing Indexes</title>
      <body>
        <p>Use the <codeph>REINDEX</codeph> command to rebuild a poorly-performing index.
            <codeph>REINDEX</codeph> rebuilds an index using the data stored in the index's table,
          replacing the old copy of the index. </p>
        <section id="im143476">
          <title>To rebuild all indexes on a table</title>
          <codeblock>REINDEX my_table;
</codeblock>
          <title>To rebuild a particular index</title>
          <codeblock>REINDEX my_index;
</codeblock>
        </section>
      </body>
    </topic>
    <topic id="topic99" xml:lang="en">
      <title>Dropping an Index</title>
      <body>
        <p>The <codeph>DROP INDEX</codeph> command removes an index. For example:</p>
        <p>
          <codeblock>DROP INDEX title_idx;
</codeblock>
        </p>
        <p>When loading data, it can be faster to drop all indexes, load, then recreate the indexes.
        </p>
      </body>
    </topic>
  </topic>
  <topic id="topic100" xml:lang="en">
    <title id="im140342">Creating and Managing Views</title>
    <body>
      <p>Views enable you to save frequently used or complex queries, then access them in a
          <codeph>SELECT</codeph> statement as if they were a table. A view is not physically
        materialized on disk: the query runs as a subquery when you access the view.</p>
      <p>If a subquery is associated with a single query, consider using the <codeph>WITH</codeph>
        clause of the <codeph>SELECT</codeph> command instead of creating a seldom-used view.</p>
    </body>
    <topic id="topic101" xml:lang="en">
      <title>Creating Views</title>
      <body>
        <p>The <codeph>CREATE VIEW </codeph>command defines a view of a query. For example:</p>
        <p>
          <codeblock>CREATE VIEW comedies AS SELECT * FROM films WHERE kind = 'comedy';
</codeblock>
        </p>
        <p>Views ignore <codeph>ORDER BY</codeph> and <codeph>SORT</codeph> operations stored in the
          view.</p>
      </body>
    </topic>
    <topic id="topic102" xml:lang="en">
      <title>Dropping Views</title>
      <body>
        <p>The <codeph>DROP VIEW</codeph> command removes a view. For example:</p>
        <p>
          <codeblock>DROP VIEW topten;
</codeblock>
        </p>
      </body>
    </topic>
  </topic>
</topic>
