<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic25">
    <title>Reading and Writing Custom-Formatted HDFS Data</title>
    <body>
        <p>Use MapReduce and the <codeph>CREATE EXTERNAL TABLE</codeph> command to read and write
            data with custom formats on HDFS.</p>
        <p>To read custom-formatted data:</p>
        <ol>
            <li id="du213746">Author and run a MapReduce job that creates a copy of the data in a
                format accessible to Greenplum Database.</li>
            <li id="du213767">Use <codeph>CREATE EXTERNAL TABLE</codeph> to read the data into
                Greenplum Database.</li>
        </ol>
        <p>See <xref href="g-example-1-read-custom-formatted-data-from-hdfs.xml#topic26"/>.</p>
        <p>To write custom-formatted data:</p>
        <ol>
            <li id="du213888">Write the data.</li>
            <li id="du213900">Author and run a MapReduce program to convert the data to the custom
                format and place it on the Hadoop Distributed File System. </li>
        </ol>
        <p>See <xref
                href="g-example-2-write-custom-formatted-data-from-greenplum-database-to-hdfs.xml#topic29"
            />.</p>
        <p>MapReduce code is written in Java. Greenplum provides Java APIs for use in the MapReduce
            code. The Javadoc is available in the <codeph>$GPHOME/docs</codeph> directory. To view
            the Javadoc, expand the file <codeph>gnet-1.1-javadoc.tar</codeph> and open
                <codeph>index.html</codeph>. The Javadoc documents the following packages:</p>
        <p>
            <codeblock>com.emc.greenplum.gpdb.hadoop.io
com.emc.greenplum.gpdb.hadoop.mapred
com.emc.greenplum.gpdb.hadoop.mapreduce.lib.input
com.emc.greenplum.gpdb.hadoop.mapreduce.lib.output
</codeblock>
        </p>
        <p>The HDFS cross-connect packages contain the Java library, which contains the packages
                <codeph>GPDBWritable</codeph>, <codeph>GPDBInputFormat</codeph>, and
                <codeph>GPDBOutputFormat</codeph>. The Java packages are available in
                <codeph>$GPHOME/lib/hadoop</codeph>. Compile and run the MapReduce job with the
            cross-connect package. For example, compile and run the MapReduce job with
                <codeph>gphd-1.0-gnet-1.0.0.1.jar</codeph> if you use the Greenplum HD 1.0
            distribution of Hadoop.</p>
        <p>To make the Java library available to all Hadoop users, the Hadoop cluster administrator
            should place the corresponding <codeph>gphdfs</codeph> connector jar in the
                <codeph>$HADOOP_HOME/lib</codeph> directory and restart the job tracker. If this is
            not done, a Hadoop user can still use the <codeph>gphdfs</codeph> connector jar; but
            with the <i>distributed cache</i> technique. </p>
    </body>
</topic>
