<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic14">
  <title>Recovering From Segment Failures</title>
  <body>
    <p>Segment host failures usually cause multiple segment failures: all primary or mirror segments
      on the host are marked as down and nonoperational. If mirroring is not enabled and a segment
      goes down, the system automatically becomes nonoperational.</p>
    <section id="ki155642">
      <title>To recover with mirroring enabled</title>
      <ol>
        <li id="ki155643">Ensure you can connect to the segment host from the master host. For
          example:<codeblock>$ ping <i>failed_seg_host_address</i></codeblock>
        </li>
        <li id="ki155645">Troubleshoot the problem that prevents the master host from connecting to
          the segment host. For example, the host machine may need to be restarted or replaced.</li>
        <li id="ki155646">After the host is online and you can connect to it, run the
            <codeph>gprecoverseg</codeph> utility from the master host to reactivate the failed
          segment instances. For example:<codeblock>$ gprecoverseg</codeblock>
        </li>
        <li id="ki158500">The recovery process brings up the failed segments and identifies the
          changed files that need to be synchronized. The process can take some time; wait for the
          process to complete. During this process, database write activity is suspended. </li>
        <li id="ki164382">After <codeph>gprecoverseg</codeph> completes, the system goes into
            <i>Resynchronizing</i> mode and begins copying the changed files. This process runs in
          the background while the system is online and accepting database requests.</li>
        <li id="ki158504">When the resynchronization process completes, the system state is
            <i>Synchronized</i>. Run the <codeph>gpstate</codeph> utility to verify the status of
          the resynchronization process:<codeblock>$ gpstate -m</codeblock>
        </li>
      </ol>
    </section>
    <section id="ki155666">
      <title>To return all segments to their preferred role</title>
      <p>When a primary segment goes down, the mirror activates and becomes the primary segment.
        After running <codeph>gprecoverseg</codeph>, the currently active segment remains the
        primary and the failed segment becomes the mirror. The segment instances are not returned to
        the preferred role that they were given at system initialization time. This means that the
        system could be in a potentially unbalanced state if segment hosts have more active segments
        than is optimal for top system performance. To check for unbalanced segments and rebalance
        the system, run:</p>
      <codeblock>$ gpstate -e</codeblock>
      <p>All segments must be online and fully synchronized to rebalance the system. Database
        sessions remain connected during rebalancing, but queries in progress are canceled and
        rolled back. </p>
      <ol>
        <li id="ki165540">Run <codeph>gpstate -m</codeph> to ensure all mirrors are
            <i>Synchronized</i>. <codeblock>$ gpstate -m</codeblock>
        </li>
        <li id="ki165577">If any mirrors are in <i>Resynchronizing</i> mode, wait for them to
          complete.</li>
        <li id="ki165591">Run gprecoverseg with the -r option to return the segments to their
          preferred roles.<codeblock>$ gprecoverseg -r</codeblock>
        </li>
        <li id="ki166668">After rebalancing, run <codeph>gpstate -e</codeph> to confirm all segments
          are in their preferred roles.<codeblock>$ gpstate -e</codeblock>
        </li>
      </ol>
    </section>
    <section id="sec-df">
      <title>To recover from a double fault</title>
      <p>In a double fault, both a primary segment and its mirror are down. This can occur if
        hardware failures on different segment hosts happen simultaneously. Greenplum Database is
        unavailable if a double fault occurs. To recover from a double fault:</p>
      <ol>
        <li id="ki165670">Restart Greenplum Database:<codeblock>$ gpstop -r</codeblock>
        </li>
        <li id="ki165671">After the system restarts, run
          <codeph>gprecoverseg</codeph>:<codeblock>$ gprecoverseg</codeblock>
        </li>
        <li id="ki165709">After <codeph>gprecoverseg</codeph> completes, use
            <codeph>gpstate</codeph> to check the status of your
          mirrors:<codeblock>$ gpstate -m</codeblock>
        </li>
        <li id="ki165730">If you still have segments in Change Tracking mode, run a full copy
          recovery:<codeblock>$ gprecoverseg -F</codeblock>
        </li>
      </ol>
      <p>If a segment host is not recoverable and you have lost one or more segments, recreate your
        Greenplum Database system from backup files. See <xref href="../../managing/backup-main.xml"
        />.</p>
    </section>
    <section>
      <title><ph>To recover without mirroring enabled</ph></title>
      <ol id="ol_lb2_rkq_kr">
        <li id="ki155667">Ensure you can connect to the segment host from the master host. For
          example:<codeblock>$ ping <i>failed_seg_host_address</i></codeblock>
        </li>
        <li id="ki155669">Troubleshoot the problem that is preventing the master host from
          connecting to the segment host. For example, the host machine may need to be
          restarted.</li>
        <li id="ki155670">After the host is online, verify that you can connect to it and restart
          Greenplum Database. For example:<codeblock>$ gpstop -r</codeblock>
        </li>
        <li id="ki155681">Run the <codeph>gpstate</codeph> utility to verify that all segment
          instances are online:<codeblock>$ gpstate</codeblock>
        </li>
      </ol>
    </section>
  </body>
</topic>
