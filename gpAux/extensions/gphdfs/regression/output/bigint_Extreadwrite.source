\echo -- start_ignore
-- start_ignore
drop  external table bigint_heap;
ERROR:  table "bigint_heap" does not exist
drop  external table bigint_writehdfs;
ERROR:  table "bigint_writehdfs" does not exist
drop  external table bigint_readhdfs;
ERROR:  table "bigint_readhdfs" does not exist
\echo -- end_ignore
-- end_ignore
create readable external table bigint_heap(datatype_bigint varchar,xcount_bigint bigint, max_bigint bigint, min_bigint bigint, x_bigint bigint, reverse_bigint bigint, increment_bigint bigint, nullcol_bigint bigint) location ('gphdfs://10.152.10.234:8020/plaintext/bigint.txt')format 'TEXT';
create writable external table bigint_writehdfs(like bigint_heap) location ('gphdfs://10.152.10.234:8020/extwrite/bigint')format 'custom' (formatter='gphdfs_export');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause, defaulting to distribution columns from LIKE table
create readable external table bigint_readhdfs(like bigint_heap) location ('gphdfs://10.152.10.234:8020/extwrite/bigint') format 'custom' (formatter='gphdfs_import');
select count(*) from bigint_heap; 
 count 
-------
  5000
(1 row)

insert into bigint_writehdfs select * from bigint_heap;
select count(*) from bigint_readhdfs;
 count 
-------
  5000
(1 row)

(select * from bigint_heap except select * from bigint_readhdfs) union (select * from bigint_readhdfs except select * from bigint_heap);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

--start_ignore
\!/usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop fs -rm -r /mapreduce/*
rm: `/mapreduce/*': No such file or directory
\!/usr/hdp/2.3.2.0-2950/hadoop/bin/hadoop fs -rm -r /mapred/*
rm: `/mapred/*': No such file or directory
--end_ignore
